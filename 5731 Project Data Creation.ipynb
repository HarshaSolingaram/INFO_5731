{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1dbec0cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\harsh\\anaconda3\\lib\\site-packages (2.28.1)\n",
      "Requirement already satisfied: PyPDF2 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (3.0.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from requests) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from requests) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from requests) (2022.9.14)\n",
      "Requirement already satisfied: typing_extensions>=3.10.0.0 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from PyPDF2) (4.10.0)\n",
      "https://aclanthology.org/2023.acl-long.11.pdf\n",
      "https://aclanthology.org/2023.acl-long.12.pdf\n",
      "https://aclanthology.org/2023.acl-long.13.pdf\n",
      "https://aclanthology.org/2023.acl-long.14.pdf\n",
      "https://aclanthology.org/2023.acl-long.15.pdf\n",
      "https://aclanthology.org/2023.acl-long.16.pdf\n",
      "https://aclanthology.org/2023.acl-long.17.pdf\n",
      "https://aclanthology.org/2023.acl-long.18.pdf\n",
      "https://aclanthology.org/2023.acl-long.19.pdf\n",
      "https://aclanthology.org/2023.acl-long.20.pdf\n",
      "https://aclanthology.org/2023.acl-long.21.pdf\n",
      "https://aclanthology.org/2023.acl-long.22.pdf\n",
      "https://aclanthology.org/2023.acl-long.23.pdf\n",
      "https://aclanthology.org/2023.acl-long.24.pdf\n",
      "https://aclanthology.org/2023.acl-long.25.pdf\n",
      "https://aclanthology.org/2023.acl-long.26.pdf\n",
      "https://aclanthology.org/2023.acl-long.27.pdf\n",
      "https://aclanthology.org/2023.acl-long.28.pdf\n",
      "https://aclanthology.org/2023.acl-long.29.pdf\n",
      "https://aclanthology.org/2023.acl-long.30.pdf\n",
      "https://aclanthology.org/2023.acl-long.31.pdf\n",
      "https://aclanthology.org/2023.acl-long.32.pdf\n",
      "https://aclanthology.org/2023.acl-long.33.pdf\n",
      "https://aclanthology.org/2023.acl-long.34.pdf\n",
      "https://aclanthology.org/2023.acl-long.35.pdf\n",
      "https://aclanthology.org/2023.acl-long.36.pdf\n",
      "https://aclanthology.org/2023.acl-long.37.pdf\n",
      "https://aclanthology.org/2023.acl-long.38.pdf\n",
      "https://aclanthology.org/2023.acl-long.39.pdf\n",
      "https://aclanthology.org/2023.acl-long.40.pdf\n",
      "https://aclanthology.org/2023.acl-long.41.pdf\n",
      "https://aclanthology.org/2023.acl-long.42.pdf\n",
      "https://aclanthology.org/2023.acl-long.43.pdf\n",
      "https://aclanthology.org/2023.acl-long.44.pdf\n",
      "https://aclanthology.org/2023.acl-long.45.pdf\n",
      "https://aclanthology.org/2023.acl-long.46.pdf\n",
      "https://aclanthology.org/2023.acl-long.47.pdf\n",
      "https://aclanthology.org/2023.acl-long.48.pdf\n",
      "https://aclanthology.org/2023.acl-long.49.pdf\n",
      "https://aclanthology.org/2023.acl-long.50.pdf\n",
      "https://aclanthology.org/2023.acl-long.51.pdf\n",
      "https://aclanthology.org/2023.acl-long.52.pdf\n",
      "https://aclanthology.org/2023.acl-long.53.pdf\n",
      "https://aclanthology.org/2023.acl-long.54.pdf\n",
      "https://aclanthology.org/2023.acl-long.55.pdf\n",
      "https://aclanthology.org/2023.acl-long.56.pdf\n",
      "https://aclanthology.org/2023.acl-long.57.pdf\n",
      "https://aclanthology.org/2023.acl-long.58.pdf\n",
      "https://aclanthology.org/2023.acl-long.59.pdf\n",
      "https://aclanthology.org/2023.acl-long.60.pdf\n",
      "https://aclanthology.org/2023.acl-long.61.pdf\n",
      "https://aclanthology.org/2023.acl-long.62.pdf\n",
      "https://aclanthology.org/2023.acl-long.63.pdf\n",
      "https://aclanthology.org/2023.acl-long.64.pdf\n",
      "https://aclanthology.org/2023.acl-long.65.pdf\n",
      "https://aclanthology.org/2023.acl-long.66.pdf\n",
      "https://aclanthology.org/2023.acl-long.67.pdf\n",
      "https://aclanthology.org/2023.acl-long.68.pdf\n",
      "https://aclanthology.org/2023.acl-long.69.pdf\n",
      "https://aclanthology.org/2023.acl-long.70.pdf\n",
      "https://aclanthology.org/2023.acl-long.71.pdf\n",
      "https://aclanthology.org/2023.acl-long.72.pdf\n",
      "https://aclanthology.org/2023.acl-long.73.pdf\n",
      "https://aclanthology.org/2023.acl-long.74.pdf\n",
      "https://aclanthology.org/2023.acl-long.75.pdf\n",
      "https://aclanthology.org/2023.acl-long.76.pdf\n",
      "https://aclanthology.org/2023.acl-long.77.pdf\n",
      "https://aclanthology.org/2023.acl-long.78.pdf\n",
      "https://aclanthology.org/2023.acl-long.79.pdf\n",
      "https://aclanthology.org/2023.acl-long.80.pdf\n",
      "https://aclanthology.org/2023.acl-long.81.pdf\n",
      "https://aclanthology.org/2023.acl-long.82.pdf\n",
      "https://aclanthology.org/2023.acl-long.83.pdf\n",
      "https://aclanthology.org/2023.acl-long.84.pdf\n",
      "https://aclanthology.org/2023.acl-long.85.pdf\n",
      "https://aclanthology.org/2023.acl-long.86.pdf\n",
      "https://aclanthology.org/2023.acl-long.87.pdf\n",
      "https://aclanthology.org/2023.acl-long.88.pdf\n",
      "https://aclanthology.org/2023.acl-long.89.pdf\n",
      "https://aclanthology.org/2023.acl-long.90.pdf\n",
      "https://aclanthology.org/2023.acl-long.91.pdf\n",
      "https://aclanthology.org/2023.acl-long.92.pdf\n",
      "https://aclanthology.org/2023.acl-long.93.pdf\n",
      "https://aclanthology.org/2023.acl-long.94.pdf\n",
      "https://aclanthology.org/2023.acl-long.95.pdf\n",
      "https://aclanthology.org/2023.acl-long.96.pdf\n",
      "https://aclanthology.org/2023.acl-long.97.pdf\n",
      "https://aclanthology.org/2023.acl-long.98.pdf\n",
      "https://aclanthology.org/2023.acl-long.99.pdf\n",
      "https://aclanthology.org/2023.acl-long.100.pdf\n",
      "https://aclanthology.org/2023.acl-long.101.pdf\n",
      "https://aclanthology.org/2023.acl-long.102.pdf\n",
      "https://aclanthology.org/2023.acl-long.103.pdf\n",
      "https://aclanthology.org/2023.acl-long.104.pdf\n",
      "https://aclanthology.org/2023.acl-long.105.pdf\n",
      "https://aclanthology.org/2023.acl-long.106.pdf\n",
      "https://aclanthology.org/2023.acl-long.107.pdf\n",
      "https://aclanthology.org/2023.acl-long.108.pdf\n",
      "https://aclanthology.org/2023.acl-long.109.pdf\n",
      "https://aclanthology.org/2023.acl-long.110.pdf\n",
      "https://aclanthology.org/2023.acl-long.111.pdf\n",
      "https://aclanthology.org/2023.acl-long.112.pdf\n",
      "https://aclanthology.org/2023.acl-long.113.pdf\n",
      "https://aclanthology.org/2023.acl-long.114.pdf\n",
      "https://aclanthology.org/2023.acl-long.115.pdf\n",
      "https://aclanthology.org/2023.acl-long.116.pdf\n",
      "https://aclanthology.org/2023.acl-long.117.pdf\n",
      "https://aclanthology.org/2023.acl-long.118.pdf\n",
      "https://aclanthology.org/2023.acl-long.119.pdf\n",
      "https://aclanthology.org/2023.acl-long.120.pdf\n",
      "https://aclanthology.org/2023.acl-long.121.pdf\n",
      "https://aclanthology.org/2023.acl-long.122.pdf\n",
      "https://aclanthology.org/2023.acl-long.123.pdf\n",
      "https://aclanthology.org/2023.acl-long.124.pdf\n",
      "https://aclanthology.org/2023.acl-long.125.pdf\n",
      "https://aclanthology.org/2023.acl-long.126.pdf\n",
      "https://aclanthology.org/2023.acl-long.127.pdf\n",
      "https://aclanthology.org/2023.acl-long.128.pdf\n",
      "https://aclanthology.org/2023.acl-long.129.pdf\n",
      "https://aclanthology.org/2023.acl-long.130.pdf\n",
      "https://aclanthology.org/2023.acl-long.131.pdf\n",
      "https://aclanthology.org/2023.acl-long.132.pdf\n",
      "https://aclanthology.org/2023.acl-long.133.pdf\n",
      "https://aclanthology.org/2023.acl-long.134.pdf\n",
      "https://aclanthology.org/2023.acl-long.135.pdf\n",
      "https://aclanthology.org/2023.acl-long.136.pdf\n",
      "https://aclanthology.org/2023.acl-long.137.pdf\n",
      "https://aclanthology.org/2023.acl-long.138.pdf\n",
      "https://aclanthology.org/2023.acl-long.139.pdf\n",
      "https://aclanthology.org/2023.acl-long.140.pdf\n",
      "https://aclanthology.org/2023.acl-long.141.pdf\n",
      "https://aclanthology.org/2023.acl-long.142.pdf\n",
      "https://aclanthology.org/2023.acl-long.143.pdf\n",
      "https://aclanthology.org/2023.acl-long.144.pdf\n",
      "https://aclanthology.org/2023.acl-long.145.pdf\n",
      "https://aclanthology.org/2023.acl-long.146.pdf\n",
      "https://aclanthology.org/2023.acl-long.147.pdf\n",
      "https://aclanthology.org/2023.acl-long.148.pdf\n",
      "https://aclanthology.org/2023.acl-long.149.pdf\n",
      "https://aclanthology.org/2023.acl-long.150.pdf\n",
      "https://aclanthology.org/2023.acl-long.151.pdf\n",
      "https://aclanthology.org/2023.acl-long.152.pdf\n",
      "https://aclanthology.org/2023.acl-long.153.pdf\n",
      "https://aclanthology.org/2023.acl-long.154.pdf\n",
      "https://aclanthology.org/2023.acl-long.155.pdf\n",
      "https://aclanthology.org/2023.acl-long.156.pdf\n",
      "https://aclanthology.org/2023.acl-long.157.pdf\n",
      "https://aclanthology.org/2023.acl-long.158.pdf\n",
      "https://aclanthology.org/2023.acl-long.159.pdf\n",
      "https://aclanthology.org/2023.acl-long.160.pdf\n",
      "https://aclanthology.org/2023.acl-long.161.pdf\n",
      "https://aclanthology.org/2023.acl-long.162.pdf\n",
      "https://aclanthology.org/2023.acl-long.163.pdf\n",
      "https://aclanthology.org/2023.acl-long.164.pdf\n",
      "https://aclanthology.org/2023.acl-long.165.pdf\n",
      "https://aclanthology.org/2023.acl-long.166.pdf\n",
      "https://aclanthology.org/2023.acl-long.167.pdf\n",
      "https://aclanthology.org/2023.acl-long.168.pdf\n",
      "https://aclanthology.org/2023.acl-long.169.pdf\n",
      "https://aclanthology.org/2023.acl-long.170.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://aclanthology.org/2023.acl-long.171.pdf\n",
      "https://aclanthology.org/2023.acl-long.172.pdf\n",
      "https://aclanthology.org/2023.acl-long.173.pdf\n",
      "https://aclanthology.org/2023.acl-long.174.pdf\n",
      "https://aclanthology.org/2023.acl-long.175.pdf\n",
      "https://aclanthology.org/2023.acl-long.176.pdf\n",
      "https://aclanthology.org/2023.acl-long.177.pdf\n",
      "https://aclanthology.org/2023.acl-long.178.pdf\n",
      "https://aclanthology.org/2023.acl-long.179.pdf\n",
      "https://aclanthology.org/2023.acl-long.180.pdf\n",
      "https://aclanthology.org/2023.acl-long.181.pdf\n",
      "https://aclanthology.org/2023.acl-long.182.pdf\n",
      "https://aclanthology.org/2023.acl-long.183.pdf\n",
      "https://aclanthology.org/2023.acl-long.184.pdf\n",
      "https://aclanthology.org/2023.acl-long.185.pdf\n",
      "https://aclanthology.org/2023.acl-long.186.pdf\n",
      "https://aclanthology.org/2023.acl-long.187.pdf\n",
      "https://aclanthology.org/2023.acl-long.188.pdf\n",
      "https://aclanthology.org/2023.acl-long.189.pdf\n",
      "https://aclanthology.org/2023.acl-long.190.pdf\n",
      "https://aclanthology.org/2023.acl-long.191.pdf\n",
      "https://aclanthology.org/2023.acl-long.192.pdf\n",
      "https://aclanthology.org/2023.acl-long.193.pdf\n",
      "https://aclanthology.org/2023.acl-long.194.pdf\n",
      "https://aclanthology.org/2023.acl-long.195.pdf\n",
      "https://aclanthology.org/2023.acl-long.196.pdf\n",
      "https://aclanthology.org/2023.acl-long.197.pdf\n",
      "https://aclanthology.org/2023.acl-long.198.pdf\n",
      "https://aclanthology.org/2023.acl-long.199.pdf\n",
      "https://aclanthology.org/2023.acl-long.200.pdf\n",
      "https://aclanthology.org/2023.acl-long.201.pdf\n",
      "https://aclanthology.org/2023.acl-long.202.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FloatObject (b'0.00-24748588') invalid; use 0.0 instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://aclanthology.org/2023.acl-long.203.pdf\n",
      "https://aclanthology.org/2023.acl-long.204.pdf\n",
      "https://aclanthology.org/2023.acl-long.205.pdf\n",
      "https://aclanthology.org/2023.acl-long.206.pdf\n",
      "https://aclanthology.org/2023.acl-long.207.pdf\n",
      "https://aclanthology.org/2023.acl-long.208.pdf\n",
      "https://aclanthology.org/2023.acl-long.209.pdf\n",
      "https://aclanthology.org/2023.acl-long.210.pdf\n",
      "https://aclanthology.org/2023.acl-long.211.pdf\n",
      "https://aclanthology.org/2023.acl-long.212.pdf\n",
      "https://aclanthology.org/2023.acl-long.213.pdf\n",
      "https://aclanthology.org/2023.acl-long.214.pdf\n",
      "https://aclanthology.org/2023.acl-long.215.pdf\n",
      "https://aclanthology.org/2023.acl-long.216.pdf\n",
      "https://aclanthology.org/2023.acl-long.217.pdf\n",
      "https://aclanthology.org/2023.acl-long.218.pdf\n",
      "https://aclanthology.org/2023.acl-long.219.pdf\n",
      "https://aclanthology.org/2023.acl-long.220.pdf\n",
      "https://aclanthology.org/2023.acl-long.221.pdf\n",
      "https://aclanthology.org/2023.acl-long.222.pdf\n",
      "https://aclanthology.org/2023.acl-long.223.pdf\n",
      "https://aclanthology.org/2023.acl-long.224.pdf\n",
      "https://aclanthology.org/2023.acl-long.225.pdf\n",
      "https://aclanthology.org/2023.acl-long.226.pdf\n",
      "https://aclanthology.org/2023.acl-long.227.pdf\n",
      "https://aclanthology.org/2023.acl-long.228.pdf\n",
      "https://aclanthology.org/2023.acl-long.229.pdf\n",
      "https://aclanthology.org/2023.acl-long.230.pdf\n",
      "https://aclanthology.org/2023.acl-long.231.pdf\n",
      "https://aclanthology.org/2023.acl-long.232.pdf\n",
      "https://aclanthology.org/2023.acl-long.233.pdf\n",
      "https://aclanthology.org/2023.acl-long.234.pdf\n",
      "https://aclanthology.org/2023.acl-long.235.pdf\n",
      "https://aclanthology.org/2023.acl-long.236.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unknown widths : \n",
      "[0, IndirectObject(2125, 0, 1792371347216)]\n",
      "unknown widths : \n",
      "[0, IndirectObject(2127, 0, 1792371347216)]\n",
      "unknown widths : \n",
      "[0, IndirectObject(2129, 0, 1792371347216)]\n",
      "unknown widths : \n",
      "[0, IndirectObject(2131, 0, 1792371347216)]\n",
      "unknown widths : \n",
      "[0, IndirectObject(2133, 0, 1792371347216)]\n",
      "unknown widths : \n",
      "[0, IndirectObject(2135, 0, 1792371347216)]\n",
      "unknown widths : \n",
      "[0, IndirectObject(2169, 0, 1792371347216)]\n",
      "unknown widths : \n",
      "[0, IndirectObject(2171, 0, 1792371347216)]\n",
      "unknown widths : \n",
      "[0, IndirectObject(2173, 0, 1792371347216)]\n",
      "unknown widths : \n",
      "[0, IndirectObject(2175, 0, 1792371347216)]\n",
      "unknown widths : \n",
      "[0, IndirectObject(2177, 0, 1792371347216)]\n",
      "unknown widths : \n",
      "[0, IndirectObject(2179, 0, 1792371347216)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://aclanthology.org/2023.acl-long.237.pdf\n",
      "https://aclanthology.org/2023.acl-long.238.pdf\n",
      "https://aclanthology.org/2023.acl-long.239.pdf\n",
      "https://aclanthology.org/2023.acl-long.240.pdf\n",
      "https://aclanthology.org/2023.acl-long.241.pdf\n",
      "https://aclanthology.org/2023.acl-long.242.pdf\n",
      "https://aclanthology.org/2023.acl-long.243.pdf\n",
      "https://aclanthology.org/2023.acl-long.244.pdf\n",
      "https://aclanthology.org/2023.acl-long.245.pdf\n",
      "https://aclanthology.org/2023.acl-long.246.pdf\n",
      "https://aclanthology.org/2023.acl-long.247.pdf\n",
      "https://aclanthology.org/2023.acl-long.248.pdf\n",
      "https://aclanthology.org/2023.acl-long.249.pdf\n",
      "https://aclanthology.org/2023.acl-long.250.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unknown widths : \n",
      "[0, IndirectObject(835, 0, 1792078248304)]\n",
      "unknown widths : \n",
      "[0, IndirectObject(839, 0, 1792078248304)]\n",
      "unknown widths : \n",
      "[0, IndirectObject(839, 0, 1792078248304)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://aclanthology.org/2023.acl-long.251.pdf\n",
      "https://aclanthology.org/2023.acl-long.252.pdf\n",
      "https://aclanthology.org/2023.acl-long.253.pdf\n",
      "https://aclanthology.org/2023.acl-long.254.pdf\n",
      "https://aclanthology.org/2023.acl-long.255.pdf\n",
      "https://aclanthology.org/2023.acl-long.256.pdf\n",
      "https://aclanthology.org/2023.acl-long.257.pdf\n",
      "https://aclanthology.org/2023.acl-long.258.pdf\n",
      "https://aclanthology.org/2023.acl-long.259.pdf\n",
      "https://aclanthology.org/2023.acl-long.260.pdf\n",
      "https://aclanthology.org/2023.acl-long.261.pdf\n",
      "https://aclanthology.org/2023.acl-long.262.pdf\n",
      "https://aclanthology.org/2023.acl-long.263.pdf\n",
      "https://aclanthology.org/2023.acl-long.264.pdf\n",
      "https://aclanthology.org/2023.acl-long.265.pdf\n",
      "https://aclanthology.org/2023.acl-long.266.pdf\n",
      "https://aclanthology.org/2023.acl-long.267.pdf\n",
      "https://aclanthology.org/2023.acl-long.268.pdf\n",
      "https://aclanthology.org/2023.acl-long.269.pdf\n",
      "https://aclanthology.org/2023.acl-long.270.pdf\n",
      "https://aclanthology.org/2023.acl-long.271.pdf\n",
      "https://aclanthology.org/2023.acl-long.272.pdf\n",
      "https://aclanthology.org/2023.acl-long.273.pdf\n",
      "https://aclanthology.org/2023.acl-long.274.pdf\n",
      "https://aclanthology.org/2023.acl-long.275.pdf\n",
      "https://aclanthology.org/2023.acl-long.276.pdf\n",
      "https://aclanthology.org/2023.acl-long.277.pdf\n",
      "https://aclanthology.org/2023.acl-long.278.pdf\n",
      "https://aclanthology.org/2023.acl-long.279.pdf\n",
      "https://aclanthology.org/2023.acl-long.280.pdf\n",
      "https://aclanthology.org/2023.acl-long.281.pdf\n",
      "https://aclanthology.org/2023.acl-long.282.pdf\n",
      "https://aclanthology.org/2023.acl-long.283.pdf\n",
      "https://aclanthology.org/2023.acl-long.284.pdf\n",
      "https://aclanthology.org/2023.acl-long.285.pdf\n",
      "https://aclanthology.org/2023.acl-long.286.pdf\n",
      "https://aclanthology.org/2023.acl-long.287.pdf\n",
      "https://aclanthology.org/2023.acl-long.288.pdf\n",
      "https://aclanthology.org/2023.acl-long.289.pdf\n",
      "https://aclanthology.org/2023.acl-long.290.pdf\n",
      "https://aclanthology.org/2023.acl-long.291.pdf\n",
      "https://aclanthology.org/2023.acl-long.292.pdf\n",
      "https://aclanthology.org/2023.acl-long.293.pdf\n",
      "https://aclanthology.org/2023.acl-long.294.pdf\n",
      "https://aclanthology.org/2023.acl-long.295.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FloatObject (b'0.00-50') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-50') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-50') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-50') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-20') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-20') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-20') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-20') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-87480317') invalid; use 0.0 instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://aclanthology.org/2023.acl-long.296.pdf\n",
      "https://aclanthology.org/2023.acl-long.297.pdf\n",
      "https://aclanthology.org/2023.acl-long.298.pdf\n",
      "https://aclanthology.org/2023.acl-long.299.pdf\n",
      "https://aclanthology.org/2023.acl-long.300.pdf\n",
      "https://aclanthology.org/2023.acl-long.301.pdf\n",
      "https://aclanthology.org/2023.acl-long.302.pdf\n",
      "https://aclanthology.org/2023.acl-long.303.pdf\n",
      "https://aclanthology.org/2023.acl-long.304.pdf\n",
      "https://aclanthology.org/2023.acl-long.305.pdf\n",
      "https://aclanthology.org/2023.acl-long.306.pdf\n",
      "https://aclanthology.org/2023.acl-long.307.pdf\n",
      "https://aclanthology.org/2023.acl-long.308.pdf\n",
      "https://aclanthology.org/2023.acl-long.309.pdf\n",
      "https://aclanthology.org/2023.acl-long.310.pdf\n",
      "https://aclanthology.org/2023.acl-long.311.pdf\n",
      "https://aclanthology.org/2023.acl-long.312.pdf\n",
      "https://aclanthology.org/2023.acl-long.313.pdf\n",
      "https://aclanthology.org/2023.acl-long.314.pdf\n",
      "https://aclanthology.org/2023.acl-long.315.pdf\n",
      "https://aclanthology.org/2023.acl-long.316.pdf\n",
      "https://aclanthology.org/2023.acl-long.317.pdf\n",
      "https://aclanthology.org/2023.acl-long.318.pdf\n",
      "https://aclanthology.org/2023.acl-long.319.pdf\n",
      "https://aclanthology.org/2023.acl-long.320.pdf\n",
      "https://aclanthology.org/2023.acl-long.321.pdf\n",
      "https://aclanthology.org/2023.acl-long.322.pdf\n",
      "https://aclanthology.org/2023.acl-long.323.pdf\n",
      "https://aclanthology.org/2023.acl-long.324.pdf\n",
      "https://aclanthology.org/2023.acl-long.325.pdf\n",
      "https://aclanthology.org/2023.acl-long.326.pdf\n",
      "https://aclanthology.org/2023.acl-long.327.pdf\n",
      "https://aclanthology.org/2023.acl-long.328.pdf\n",
      "https://aclanthology.org/2023.acl-long.329.pdf\n",
      "https://aclanthology.org/2023.acl-long.330.pdf\n",
      "https://aclanthology.org/2023.acl-long.331.pdf\n",
      "https://aclanthology.org/2023.acl-long.332.pdf\n",
      "https://aclanthology.org/2023.acl-long.333.pdf\n",
      "https://aclanthology.org/2023.acl-long.334.pdf\n",
      "https://aclanthology.org/2023.acl-long.335.pdf\n",
      "https://aclanthology.org/2023.acl-long.336.pdf\n",
      "https://aclanthology.org/2023.acl-long.337.pdf\n",
      "https://aclanthology.org/2023.acl-long.338.pdf\n",
      "https://aclanthology.org/2023.acl-long.339.pdf\n",
      "https://aclanthology.org/2023.acl-long.340.pdf\n",
      "https://aclanthology.org/2023.acl-long.341.pdf\n",
      "https://aclanthology.org/2023.acl-long.342.pdf\n",
      "https://aclanthology.org/2023.acl-long.343.pdf\n",
      "https://aclanthology.org/2023.acl-long.344.pdf\n",
      "https://aclanthology.org/2023.acl-long.345.pdf\n",
      "https://aclanthology.org/2023.acl-long.346.pdf\n",
      "https://aclanthology.org/2023.acl-long.347.pdf\n",
      "https://aclanthology.org/2023.acl-long.348.pdf\n",
      "https://aclanthology.org/2023.acl-long.349.pdf\n",
      "https://aclanthology.org/2023.acl-long.350.pdf\n",
      "https://aclanthology.org/2023.acl-long.351.pdf\n",
      "https://aclanthology.org/2023.acl-long.352.pdf\n",
      "https://aclanthology.org/2023.acl-long.353.pdf\n",
      "https://aclanthology.org/2023.acl-long.354.pdf\n",
      "https://aclanthology.org/2023.acl-long.355.pdf\n",
      "https://aclanthology.org/2023.acl-long.356.pdf\n",
      "https://aclanthology.org/2023.acl-long.357.pdf\n",
      "https://aclanthology.org/2023.acl-long.358.pdf\n",
      "https://aclanthology.org/2023.acl-long.359.pdf\n",
      "https://aclanthology.org/2023.acl-long.360.pdf\n",
      "https://aclanthology.org/2023.acl-long.361.pdf\n",
      "https://aclanthology.org/2023.acl-long.362.pdf\n",
      "https://aclanthology.org/2023.acl-long.363.pdf\n",
      "https://aclanthology.org/2023.acl-long.364.pdf\n",
      "https://aclanthology.org/2023.acl-long.365.pdf\n",
      "https://aclanthology.org/2023.acl-long.366.pdf\n",
      "https://aclanthology.org/2023.acl-long.367.pdf\n",
      "https://aclanthology.org/2023.acl-long.368.pdf\n",
      "https://aclanthology.org/2023.acl-long.369.pdf\n",
      "https://aclanthology.org/2023.acl-long.370.pdf\n",
      "https://aclanthology.org/2023.acl-long.371.pdf\n",
      "https://aclanthology.org/2023.acl-long.372.pdf\n",
      "https://aclanthology.org/2023.acl-long.373.pdf\n",
      "https://aclanthology.org/2023.acl-long.374.pdf\n",
      "https://aclanthology.org/2023.acl-long.375.pdf\n",
      "https://aclanthology.org/2023.acl-long.376.pdf\n",
      "https://aclanthology.org/2023.acl-long.377.pdf\n",
      "https://aclanthology.org/2023.acl-long.378.pdf\n",
      "https://aclanthology.org/2023.acl-long.379.pdf\n",
      "https://aclanthology.org/2023.acl-long.380.pdf\n",
      "https://aclanthology.org/2023.acl-long.381.pdf\n",
      "https://aclanthology.org/2023.acl-long.382.pdf\n",
      "https://aclanthology.org/2023.acl-long.383.pdf\n",
      "https://aclanthology.org/2023.acl-long.384.pdf\n",
      "https://aclanthology.org/2023.acl-long.385.pdf\n",
      "https://aclanthology.org/2023.acl-long.386.pdf\n",
      "https://aclanthology.org/2023.acl-long.387.pdf\n",
      "https://aclanthology.org/2023.acl-long.388.pdf\n",
      "https://aclanthology.org/2023.acl-long.389.pdf\n",
      "https://aclanthology.org/2023.acl-long.390.pdf\n",
      "https://aclanthology.org/2023.acl-long.391.pdf\n",
      "https://aclanthology.org/2023.acl-long.392.pdf\n",
      "https://aclanthology.org/2023.acl-long.393.pdf\n",
      "https://aclanthology.org/2023.acl-long.394.pdf\n",
      "https://aclanthology.org/2023.acl-long.395.pdf\n",
      "https://aclanthology.org/2023.acl-long.396.pdf\n",
      "https://aclanthology.org/2023.acl-long.397.pdf\n",
      "https://aclanthology.org/2023.acl-long.398.pdf\n",
      "https://aclanthology.org/2023.acl-long.399.pdf\n",
      "https://aclanthology.org/2023.acl-long.400.pdf\n",
      "https://aclanthology.org/2023.acl-long.401.pdf\n",
      "https://aclanthology.org/2023.acl-long.402.pdf\n",
      "https://aclanthology.org/2023.acl-long.403.pdf\n",
      "https://aclanthology.org/2023.acl-long.404.pdf\n",
      "https://aclanthology.org/2023.acl-long.405.pdf\n",
      "https://aclanthology.org/2023.acl-long.406.pdf\n",
      "https://aclanthology.org/2023.acl-long.407.pdf\n",
      "https://aclanthology.org/2023.acl-long.408.pdf\n",
      "https://aclanthology.org/2023.acl-long.409.pdf\n",
      "https://aclanthology.org/2023.acl-long.410.pdf\n",
      "https://aclanthology.org/2023.acl-long.411.pdf\n",
      "https://aclanthology.org/2023.acl-long.412.pdf\n",
      "https://aclanthology.org/2023.acl-long.413.pdf\n",
      "https://aclanthology.org/2023.acl-long.414.pdf\n",
      "https://aclanthology.org/2023.acl-long.415.pdf\n",
      "https://aclanthology.org/2023.acl-long.416.pdf\n",
      "https://aclanthology.org/2023.acl-long.417.pdf\n",
      "https://aclanthology.org/2023.acl-long.418.pdf\n",
      "https://aclanthology.org/2023.acl-long.419.pdf\n",
      "https://aclanthology.org/2023.acl-long.420.pdf\n",
      "https://aclanthology.org/2023.acl-long.421.pdf\n",
      "https://aclanthology.org/2023.acl-long.422.pdf\n",
      "https://aclanthology.org/2023.acl-long.423.pdf\n",
      "https://aclanthology.org/2023.acl-long.424.pdf\n",
      "https://aclanthology.org/2023.acl-long.425.pdf\n",
      "https://aclanthology.org/2023.acl-long.426.pdf\n",
      "https://aclanthology.org/2023.acl-long.427.pdf\n",
      "https://aclanthology.org/2023.acl-long.428.pdf\n",
      "https://aclanthology.org/2023.acl-long.429.pdf\n",
      "https://aclanthology.org/2023.acl-long.430.pdf\n",
      "https://aclanthology.org/2023.acl-long.431.pdf\n",
      "https://aclanthology.org/2023.acl-long.432.pdf\n",
      "https://aclanthology.org/2023.acl-long.433.pdf\n",
      "https://aclanthology.org/2023.acl-long.434.pdf\n",
      "https://aclanthology.org/2023.acl-long.435.pdf\n",
      "https://aclanthology.org/2023.acl-long.436.pdf\n",
      "https://aclanthology.org/2023.acl-long.437.pdf\n",
      "https://aclanthology.org/2023.acl-long.438.pdf\n",
      "https://aclanthology.org/2023.acl-long.439.pdf\n",
      "https://aclanthology.org/2023.acl-long.440.pdf\n",
      "https://aclanthology.org/2023.acl-long.441.pdf\n",
      "https://aclanthology.org/2023.acl-long.442.pdf\n",
      "https://aclanthology.org/2023.acl-long.443.pdf\n",
      "https://aclanthology.org/2023.acl-long.444.pdf\n",
      "https://aclanthology.org/2023.acl-long.445.pdf\n",
      "https://aclanthology.org/2023.acl-long.446.pdf\n",
      "https://aclanthology.org/2023.acl-long.447.pdf\n",
      "https://aclanthology.org/2023.acl-long.448.pdf\n",
      "https://aclanthology.org/2023.acl-long.449.pdf\n",
      "https://aclanthology.org/2023.acl-long.450.pdf\n",
      "https://aclanthology.org/2023.acl-long.451.pdf\n",
      "https://aclanthology.org/2023.acl-long.452.pdf\n",
      "https://aclanthology.org/2023.acl-long.453.pdf\n",
      "https://aclanthology.org/2023.acl-long.454.pdf\n",
      "https://aclanthology.org/2023.acl-long.455.pdf\n",
      "https://aclanthology.org/2023.acl-long.456.pdf\n",
      "https://aclanthology.org/2023.acl-long.457.pdf\n",
      "https://aclanthology.org/2023.acl-long.458.pdf\n",
      "https://aclanthology.org/2023.acl-long.459.pdf\n",
      "https://aclanthology.org/2023.acl-long.460.pdf\n",
      "https://aclanthology.org/2023.acl-long.461.pdf\n",
      "https://aclanthology.org/2023.acl-long.462.pdf\n",
      "https://aclanthology.org/2023.acl-long.463.pdf\n",
      "https://aclanthology.org/2023.acl-long.464.pdf\n",
      "https://aclanthology.org/2023.acl-long.465.pdf\n",
      "https://aclanthology.org/2023.acl-long.466.pdf\n",
      "https://aclanthology.org/2023.acl-long.467.pdf\n",
      "https://aclanthology.org/2023.acl-long.468.pdf\n",
      "https://aclanthology.org/2023.acl-long.469.pdf\n",
      "https://aclanthology.org/2023.acl-long.470.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://aclanthology.org/2023.acl-long.471.pdf\n",
      "https://aclanthology.org/2023.acl-long.472.pdf\n",
      "https://aclanthology.org/2023.acl-long.473.pdf\n",
      "https://aclanthology.org/2023.acl-long.474.pdf\n",
      "https://aclanthology.org/2023.acl-long.475.pdf\n",
      "https://aclanthology.org/2023.acl-long.476.pdf\n",
      "https://aclanthology.org/2023.acl-long.477.pdf\n",
      "https://aclanthology.org/2023.acl-long.478.pdf\n",
      "https://aclanthology.org/2023.acl-long.479.pdf\n",
      "https://aclanthology.org/2023.acl-long.480.pdf\n",
      "https://aclanthology.org/2023.acl-long.481.pdf\n",
      "https://aclanthology.org/2023.acl-long.482.pdf\n",
      "https://aclanthology.org/2023.acl-long.483.pdf\n",
      "https://aclanthology.org/2023.acl-long.484.pdf\n",
      "https://aclanthology.org/2023.acl-long.485.pdf\n",
      "https://aclanthology.org/2023.acl-long.486.pdf\n",
      "https://aclanthology.org/2023.acl-long.487.pdf\n",
      "https://aclanthology.org/2023.acl-long.488.pdf\n",
      "https://aclanthology.org/2023.acl-long.489.pdf\n",
      "https://aclanthology.org/2023.acl-long.490.pdf\n",
      "https://aclanthology.org/2023.acl-long.491.pdf\n",
      "https://aclanthology.org/2023.acl-long.492.pdf\n",
      "https://aclanthology.org/2023.acl-long.493.pdf\n",
      "https://aclanthology.org/2023.acl-long.494.pdf\n",
      "https://aclanthology.org/2023.acl-long.495.pdf\n",
      "https://aclanthology.org/2023.acl-long.496.pdf\n",
      "https://aclanthology.org/2023.acl-long.497.pdf\n",
      "https://aclanthology.org/2023.acl-long.498.pdf\n",
      "https://aclanthology.org/2023.acl-long.499.pdf\n",
      "https://aclanthology.org/2023.acl-long.500.pdf\n",
      "https://aclanthology.org/2023.acl-long.501.pdf\n",
      "https://aclanthology.org/2023.acl-long.502.pdf\n",
      "https://aclanthology.org/2023.acl-long.503.pdf\n",
      "https://aclanthology.org/2023.acl-long.504.pdf\n",
      "https://aclanthology.org/2023.acl-long.505.pdf\n",
      "https://aclanthology.org/2023.acl-long.506.pdf\n",
      "https://aclanthology.org/2023.acl-long.507.pdf\n",
      "https://aclanthology.org/2023.acl-long.508.pdf\n",
      "https://aclanthology.org/2023.acl-long.509.pdf\n",
      "https://aclanthology.org/2023.acl-long.510.pdf\n",
      "https://aclanthology.org/2023.acl-long.511.pdf\n",
      "https://aclanthology.org/2023.acl-long.512.pdf\n",
      "https://aclanthology.org/2023.acl-long.513.pdf\n",
      "https://aclanthology.org/2023.acl-long.514.pdf\n",
      "https://aclanthology.org/2023.acl-long.515.pdf\n",
      "https://aclanthology.org/2023.acl-long.516.pdf\n",
      "https://aclanthology.org/2023.acl-long.517.pdf\n",
      "https://aclanthology.org/2023.acl-long.518.pdf\n",
      "https://aclanthology.org/2023.acl-long.519.pdf\n",
      "https://aclanthology.org/2023.acl-long.520.pdf\n",
      "https://aclanthology.org/2023.acl-long.521.pdf\n",
      "https://aclanthology.org/2023.acl-long.522.pdf\n",
      "https://aclanthology.org/2023.acl-long.523.pdf\n",
      "https://aclanthology.org/2023.acl-long.524.pdf\n",
      "https://aclanthology.org/2023.acl-long.525.pdf\n",
      "https://aclanthology.org/2023.acl-long.526.pdf\n",
      "https://aclanthology.org/2023.acl-long.527.pdf\n",
      "https://aclanthology.org/2023.acl-long.528.pdf\n",
      "https://aclanthology.org/2023.acl-long.529.pdf\n",
      "https://aclanthology.org/2023.acl-long.530.pdf\n",
      "https://aclanthology.org/2023.acl-long.531.pdf\n",
      "https://aclanthology.org/2023.acl-long.532.pdf\n",
      "https://aclanthology.org/2023.acl-long.533.pdf\n",
      "https://aclanthology.org/2023.acl-long.534.pdf\n",
      "https://aclanthology.org/2023.acl-long.535.pdf\n",
      "https://aclanthology.org/2023.acl-long.536.pdf\n",
      "https://aclanthology.org/2023.acl-long.537.pdf\n",
      "https://aclanthology.org/2023.acl-long.538.pdf\n",
      "https://aclanthology.org/2023.acl-long.539.pdf\n",
      "https://aclanthology.org/2023.acl-long.540.pdf\n",
      "https://aclanthology.org/2023.acl-long.541.pdf\n",
      "https://aclanthology.org/2023.acl-long.542.pdf\n",
      "https://aclanthology.org/2023.acl-long.543.pdf\n",
      "https://aclanthology.org/2023.acl-long.544.pdf\n",
      "https://aclanthology.org/2023.acl-long.545.pdf\n",
      "https://aclanthology.org/2023.acl-long.546.pdf\n",
      "https://aclanthology.org/2023.acl-long.547.pdf\n",
      "https://aclanthology.org/2023.acl-long.548.pdf\n",
      "https://aclanthology.org/2023.acl-long.549.pdf\n",
      "https://aclanthology.org/2023.acl-long.550.pdf\n",
      "https://aclanthology.org/2023.acl-long.551.pdf\n",
      "https://aclanthology.org/2023.acl-long.552.pdf\n",
      "https://aclanthology.org/2023.acl-long.553.pdf\n",
      "https://aclanthology.org/2023.acl-long.554.pdf\n",
      "https://aclanthology.org/2023.acl-long.555.pdf\n",
      "https://aclanthology.org/2023.acl-long.556.pdf\n",
      "https://aclanthology.org/2023.acl-long.557.pdf\n",
      "https://aclanthology.org/2023.acl-long.558.pdf\n",
      "https://aclanthology.org/2023.acl-long.559.pdf\n",
      "https://aclanthology.org/2023.acl-long.560.pdf\n",
      "https://aclanthology.org/2023.acl-long.561.pdf\n",
      "https://aclanthology.org/2023.acl-long.562.pdf\n",
      "https://aclanthology.org/2023.acl-long.563.pdf\n",
      "https://aclanthology.org/2023.acl-long.564.pdf\n",
      "https://aclanthology.org/2023.acl-long.565.pdf\n",
      "https://aclanthology.org/2023.acl-long.566.pdf\n",
      "https://aclanthology.org/2023.acl-long.567.pdf\n",
      "https://aclanthology.org/2023.acl-long.568.pdf\n",
      "https://aclanthology.org/2023.acl-long.569.pdf\n",
      "https://aclanthology.org/2023.acl-long.570.pdf\n",
      "https://aclanthology.org/2023.acl-long.571.pdf\n",
      "https://aclanthology.org/2023.acl-long.572.pdf\n",
      "https://aclanthology.org/2023.acl-long.573.pdf\n",
      "https://aclanthology.org/2023.acl-long.574.pdf\n",
      "https://aclanthology.org/2023.acl-long.575.pdf\n",
      "https://aclanthology.org/2023.acl-long.576.pdf\n",
      "https://aclanthology.org/2023.acl-long.577.pdf\n",
      "https://aclanthology.org/2023.acl-long.578.pdf\n",
      "https://aclanthology.org/2023.acl-long.579.pdf\n",
      "https://aclanthology.org/2023.acl-long.580.pdf\n",
      "https://aclanthology.org/2023.acl-long.581.pdf\n",
      "https://aclanthology.org/2023.acl-long.582.pdf\n",
      "https://aclanthology.org/2023.acl-long.583.pdf\n",
      "https://aclanthology.org/2023.acl-long.584.pdf\n",
      "https://aclanthology.org/2023.acl-long.585.pdf\n",
      "https://aclanthology.org/2023.acl-long.586.pdf\n",
      "https://aclanthology.org/2023.acl-long.587.pdf\n",
      "https://aclanthology.org/2023.acl-long.588.pdf\n",
      "https://aclanthology.org/2023.acl-long.589.pdf\n",
      "https://aclanthology.org/2023.acl-long.590.pdf\n",
      "https://aclanthology.org/2023.acl-long.591.pdf\n",
      "https://aclanthology.org/2023.acl-long.592.pdf\n",
      "https://aclanthology.org/2023.acl-long.593.pdf\n",
      "https://aclanthology.org/2023.acl-long.594.pdf\n",
      "https://aclanthology.org/2023.acl-long.595.pdf\n",
      "https://aclanthology.org/2023.acl-long.596.pdf\n",
      "https://aclanthology.org/2023.acl-long.597.pdf\n",
      "https://aclanthology.org/2023.acl-long.598.pdf\n",
      "https://aclanthology.org/2023.acl-long.599.pdf\n",
      "https://aclanthology.org/2023.acl-long.600.pdf\n",
      "https://aclanthology.org/2023.acl-long.601.pdf\n",
      "https://aclanthology.org/2023.acl-long.602.pdf\n",
      "https://aclanthology.org/2023.acl-long.603.pdf\n",
      "https://aclanthology.org/2023.acl-long.604.pdf\n",
      "https://aclanthology.org/2023.acl-long.605.pdf\n",
      "https://aclanthology.org/2023.acl-long.606.pdf\n",
      "https://aclanthology.org/2023.acl-long.607.pdf\n",
      "https://aclanthology.org/2023.acl-long.608.pdf\n",
      "https://aclanthology.org/2023.acl-long.609.pdf\n",
      "https://aclanthology.org/2023.acl-long.610.pdf\n",
      "https://aclanthology.org/2023.acl-long.611.pdf\n",
      "https://aclanthology.org/2023.acl-long.612.pdf\n",
      "https://aclanthology.org/2023.acl-long.613.pdf\n",
      "https://aclanthology.org/2023.acl-long.614.pdf\n",
      "https://aclanthology.org/2023.acl-long.615.pdf\n",
      "https://aclanthology.org/2023.acl-long.616.pdf\n",
      "https://aclanthology.org/2023.acl-long.617.pdf\n",
      "https://aclanthology.org/2023.acl-long.618.pdf\n",
      "https://aclanthology.org/2023.acl-long.619.pdf\n",
      "https://aclanthology.org/2023.acl-long.620.pdf\n",
      "https://aclanthology.org/2023.acl-long.621.pdf\n",
      "https://aclanthology.org/2023.acl-long.622.pdf\n",
      "https://aclanthology.org/2023.acl-long.623.pdf\n",
      "https://aclanthology.org/2023.acl-long.624.pdf\n",
      "https://aclanthology.org/2023.acl-long.625.pdf\n",
      "https://aclanthology.org/2023.acl-long.626.pdf\n",
      "https://aclanthology.org/2023.acl-long.627.pdf\n",
      "https://aclanthology.org/2023.acl-long.628.pdf\n",
      "https://aclanthology.org/2023.acl-long.629.pdf\n",
      "https://aclanthology.org/2023.acl-long.630.pdf\n",
      "https://aclanthology.org/2023.acl-long.631.pdf\n",
      "https://aclanthology.org/2023.acl-long.632.pdf\n",
      "https://aclanthology.org/2023.acl-long.633.pdf\n",
      "https://aclanthology.org/2023.acl-long.634.pdf\n",
      "https://aclanthology.org/2023.acl-long.635.pdf\n",
      "https://aclanthology.org/2023.acl-long.636.pdf\n",
      "https://aclanthology.org/2023.acl-long.637.pdf\n",
      "https://aclanthology.org/2023.acl-long.638.pdf\n",
      "https://aclanthology.org/2023.acl-long.639.pdf\n",
      "https://aclanthology.org/2023.acl-long.640.pdf\n",
      "https://aclanthology.org/2023.acl-long.641.pdf\n",
      "https://aclanthology.org/2023.acl-long.642.pdf\n",
      "https://aclanthology.org/2023.acl-long.643.pdf\n",
      "https://aclanthology.org/2023.acl-long.644.pdf\n",
      "https://aclanthology.org/2023.acl-long.645.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://aclanthology.org/2023.acl-long.646.pdf\n",
      "https://aclanthology.org/2023.acl-long.647.pdf\n",
      "https://aclanthology.org/2023.acl-long.648.pdf\n",
      "https://aclanthology.org/2023.acl-long.649.pdf\n",
      "https://aclanthology.org/2023.acl-long.650.pdf\n",
      "https://aclanthology.org/2023.acl-long.651.pdf\n",
      "https://aclanthology.org/2023.acl-long.652.pdf\n",
      "https://aclanthology.org/2023.acl-long.653.pdf\n",
      "https://aclanthology.org/2023.acl-long.654.pdf\n",
      "https://aclanthology.org/2023.acl-long.655.pdf\n",
      "https://aclanthology.org/2023.acl-long.656.pdf\n",
      "https://aclanthology.org/2023.acl-long.657.pdf\n",
      "https://aclanthology.org/2023.acl-long.658.pdf\n",
      "https://aclanthology.org/2023.acl-long.659.pdf\n",
      "https://aclanthology.org/2023.acl-long.660.pdf\n",
      "https://aclanthology.org/2023.acl-long.661.pdf\n",
      "https://aclanthology.org/2023.acl-long.662.pdf\n",
      "https://aclanthology.org/2023.acl-long.663.pdf\n",
      "https://aclanthology.org/2023.acl-long.664.pdf\n",
      "https://aclanthology.org/2023.acl-long.665.pdf\n",
      "https://aclanthology.org/2023.acl-long.666.pdf\n",
      "https://aclanthology.org/2023.acl-long.667.pdf\n",
      "https://aclanthology.org/2023.acl-long.668.pdf\n",
      "https://aclanthology.org/2023.acl-long.669.pdf\n",
      "https://aclanthology.org/2023.acl-long.670.pdf\n",
      "https://aclanthology.org/2023.acl-long.671.pdf\n",
      "https://aclanthology.org/2023.acl-long.672.pdf\n",
      "https://aclanthology.org/2023.acl-long.673.pdf\n",
      "https://aclanthology.org/2023.acl-long.674.pdf\n",
      "https://aclanthology.org/2023.acl-long.675.pdf\n",
      "https://aclanthology.org/2023.acl-long.676.pdf\n",
      "https://aclanthology.org/2023.acl-long.677.pdf\n",
      "https://aclanthology.org/2023.acl-long.678.pdf\n",
      "https://aclanthology.org/2023.acl-long.679.pdf\n",
      "https://aclanthology.org/2023.acl-long.680.pdf\n",
      "https://aclanthology.org/2023.acl-long.681.pdf\n",
      "https://aclanthology.org/2023.acl-long.682.pdf\n",
      "https://aclanthology.org/2023.acl-long.683.pdf\n",
      "https://aclanthology.org/2023.acl-long.684.pdf\n",
      "https://aclanthology.org/2023.acl-long.685.pdf\n",
      "https://aclanthology.org/2023.acl-long.686.pdf\n",
      "https://aclanthology.org/2023.acl-long.687.pdf\n",
      "https://aclanthology.org/2023.acl-long.688.pdf\n",
      "https://aclanthology.org/2023.acl-long.689.pdf\n",
      "https://aclanthology.org/2023.acl-long.690.pdf\n",
      "https://aclanthology.org/2023.acl-long.691.pdf\n",
      "https://aclanthology.org/2023.acl-long.692.pdf\n",
      "https://aclanthology.org/2023.acl-long.693.pdf\n",
      "https://aclanthology.org/2023.acl-long.694.pdf\n",
      "https://aclanthology.org/2023.acl-long.695.pdf\n",
      "https://aclanthology.org/2023.acl-long.696.pdf\n",
      "https://aclanthology.org/2023.acl-long.697.pdf\n",
      "https://aclanthology.org/2023.acl-long.698.pdf\n",
      "https://aclanthology.org/2023.acl-long.699.pdf\n",
      "https://aclanthology.org/2023.acl-long.700.pdf\n",
      "https://aclanthology.org/2023.acl-long.701.pdf\n",
      "https://aclanthology.org/2023.acl-long.702.pdf\n",
      "https://aclanthology.org/2023.acl-long.703.pdf\n",
      "https://aclanthology.org/2023.acl-long.704.pdf\n",
      "https://aclanthology.org/2023.acl-long.705.pdf\n",
      "https://aclanthology.org/2023.acl-long.706.pdf\n",
      "https://aclanthology.org/2023.acl-long.707.pdf\n",
      "https://aclanthology.org/2023.acl-long.708.pdf\n",
      "https://aclanthology.org/2023.acl-long.709.pdf\n",
      "https://aclanthology.org/2023.acl-long.710.pdf\n",
      "https://aclanthology.org/2023.acl-long.711.pdf\n",
      "https://aclanthology.org/2023.acl-long.712.pdf\n",
      "https://aclanthology.org/2023.acl-long.713.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FloatObject (b'0.0000000-37252903') invalid; use 0.0 instead\n",
      "FloatObject (b'0.0000000-37252903') invalid; use 0.0 instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://aclanthology.org/2023.acl-long.714.pdf\n",
      "https://aclanthology.org/2023.acl-long.715.pdf\n",
      "https://aclanthology.org/2023.acl-long.716.pdf\n",
      "https://aclanthology.org/2023.acl-long.717.pdf\n",
      "https://aclanthology.org/2023.acl-long.718.pdf\n",
      "https://aclanthology.org/2023.acl-long.719.pdf\n",
      "https://aclanthology.org/2023.acl-long.720.pdf\n",
      "https://aclanthology.org/2023.acl-long.721.pdf\n",
      "https://aclanthology.org/2023.acl-long.722.pdf\n",
      "https://aclanthology.org/2023.acl-long.723.pdf\n",
      "https://aclanthology.org/2023.acl-long.724.pdf\n",
      "https://aclanthology.org/2023.acl-long.725.pdf\n",
      "https://aclanthology.org/2023.acl-long.726.pdf\n",
      "https://aclanthology.org/2023.acl-long.727.pdf\n",
      "https://aclanthology.org/2023.acl-long.728.pdf\n",
      "https://aclanthology.org/2023.acl-long.729.pdf\n",
      "https://aclanthology.org/2023.acl-long.730.pdf\n",
      "https://aclanthology.org/2023.acl-long.731.pdf\n",
      "https://aclanthology.org/2023.acl-long.732.pdf\n",
      "https://aclanthology.org/2023.acl-long.733.pdf\n",
      "https://aclanthology.org/2023.acl-long.734.pdf\n",
      "https://aclanthology.org/2023.acl-long.735.pdf\n",
      "https://aclanthology.org/2023.acl-long.736.pdf\n",
      "https://aclanthology.org/2023.acl-long.737.pdf\n",
      "https://aclanthology.org/2023.acl-long.738.pdf\n",
      "https://aclanthology.org/2023.acl-long.739.pdf\n",
      "https://aclanthology.org/2023.acl-long.740.pdf\n",
      "https://aclanthology.org/2023.acl-long.741.pdf\n",
      "https://aclanthology.org/2023.acl-long.742.pdf\n",
      "https://aclanthology.org/2023.acl-long.743.pdf\n",
      "https://aclanthology.org/2023.acl-long.744.pdf\n",
      "https://aclanthology.org/2023.acl-long.745.pdf\n",
      "https://aclanthology.org/2023.acl-long.746.pdf\n",
      "https://aclanthology.org/2023.acl-long.747.pdf\n",
      "https://aclanthology.org/2023.acl-long.748.pdf\n",
      "https://aclanthology.org/2023.acl-long.749.pdf\n",
      "https://aclanthology.org/2023.acl-long.750.pdf\n",
      "https://aclanthology.org/2023.acl-long.751.pdf\n",
      "https://aclanthology.org/2023.acl-long.752.pdf\n",
      "https://aclanthology.org/2023.acl-long.753.pdf\n",
      "https://aclanthology.org/2023.acl-long.754.pdf\n",
      "https://aclanthology.org/2023.acl-long.755.pdf\n",
      "https://aclanthology.org/2023.acl-long.756.pdf\n",
      "https://aclanthology.org/2023.acl-long.757.pdf\n",
      "https://aclanthology.org/2023.acl-long.758.pdf\n",
      "https://aclanthology.org/2023.acl-long.759.pdf\n",
      "https://aclanthology.org/2023.acl-long.760.pdf\n",
      "https://aclanthology.org/2023.acl-long.761.pdf\n",
      "https://aclanthology.org/2023.acl-long.762.pdf\n",
      "https://aclanthology.org/2023.acl-long.763.pdf\n",
      "https://aclanthology.org/2023.acl-long.764.pdf\n",
      "https://aclanthology.org/2023.acl-long.765.pdf\n",
      "https://aclanthology.org/2023.acl-long.766.pdf\n",
      "https://aclanthology.org/2023.acl-long.767.pdf\n",
      "https://aclanthology.org/2023.acl-long.768.pdf\n",
      "https://aclanthology.org/2023.acl-long.769.pdf\n",
      "https://aclanthology.org/2023.acl-long.770.pdf\n",
      "https://aclanthology.org/2023.acl-long.771.pdf\n",
      "https://aclanthology.org/2023.acl-long.772.pdf\n",
      "https://aclanthology.org/2023.acl-long.773.pdf\n",
      "https://aclanthology.org/2023.acl-long.774.pdf\n",
      "https://aclanthology.org/2023.acl-long.775.pdf\n",
      "https://aclanthology.org/2023.acl-long.776.pdf\n",
      "https://aclanthology.org/2023.acl-long.777.pdf\n",
      "https://aclanthology.org/2023.acl-long.778.pdf\n",
      "https://aclanthology.org/2023.acl-long.779.pdf\n",
      "https://aclanthology.org/2023.acl-long.780.pdf\n",
      "https://aclanthology.org/2023.acl-long.781.pdf\n",
      "https://aclanthology.org/2023.acl-long.782.pdf\n",
      "https://aclanthology.org/2023.acl-long.783.pdf\n",
      "https://aclanthology.org/2023.acl-long.784.pdf\n",
      "https://aclanthology.org/2023.acl-long.785.pdf\n",
      "https://aclanthology.org/2023.acl-long.786.pdf\n",
      "https://aclanthology.org/2023.acl-long.787.pdf\n",
      "https://aclanthology.org/2023.acl-long.788.pdf\n",
      "https://aclanthology.org/2023.acl-long.789.pdf\n",
      "https://aclanthology.org/2023.acl-long.790.pdf\n",
      "https://aclanthology.org/2023.acl-long.791.pdf\n",
      "https://aclanthology.org/2023.acl-long.792.pdf\n",
      "https://aclanthology.org/2023.acl-long.793.pdf\n",
      "https://aclanthology.org/2023.acl-long.794.pdf\n",
      "https://aclanthology.org/2023.acl-long.795.pdf\n",
      "https://aclanthology.org/2023.acl-long.796.pdf\n",
      "https://aclanthology.org/2023.acl-long.797.pdf\n",
      "https://aclanthology.org/2023.acl-long.798.pdf\n",
      "https://aclanthology.org/2023.acl-long.799.pdf\n",
      "https://aclanthology.org/2023.acl-long.800.pdf\n",
      "https://aclanthology.org/2023.acl-long.801.pdf\n",
      "https://aclanthology.org/2023.acl-long.802.pdf\n",
      "https://aclanthology.org/2023.acl-long.803.pdf\n",
      "https://aclanthology.org/2023.acl-long.804.pdf\n",
      "https://aclanthology.org/2023.acl-long.805.pdf\n",
      "https://aclanthology.org/2023.acl-long.806.pdf\n",
      "https://aclanthology.org/2023.acl-long.807.pdf\n",
      "https://aclanthology.org/2023.acl-long.808.pdf\n",
      "https://aclanthology.org/2023.acl-long.809.pdf\n",
      "https://aclanthology.org/2023.acl-long.810.pdf\n",
      "https://aclanthology.org/2023.acl-long.811.pdf\n",
      "https://aclanthology.org/2023.acl-long.812.pdf\n",
      "https://aclanthology.org/2023.acl-long.813.pdf\n",
      "https://aclanthology.org/2023.acl-long.814.pdf\n",
      "https://aclanthology.org/2023.acl-long.815.pdf\n",
      "https://aclanthology.org/2023.acl-long.816.pdf\n",
      "https://aclanthology.org/2023.acl-long.817.pdf\n",
      "https://aclanthology.org/2023.acl-long.818.pdf\n",
      "https://aclanthology.org/2023.acl-long.819.pdf\n",
      "https://aclanthology.org/2023.acl-long.820.pdf\n",
      "https://aclanthology.org/2023.acl-long.821.pdf\n",
      "https://aclanthology.org/2023.acl-long.822.pdf\n",
      "https://aclanthology.org/2023.acl-long.823.pdf\n",
      "https://aclanthology.org/2023.acl-long.824.pdf\n",
      "https://aclanthology.org/2023.acl-long.825.pdf\n",
      "https://aclanthology.org/2023.acl-long.826.pdf\n",
      "https://aclanthology.org/2023.acl-long.827.pdf\n",
      "https://aclanthology.org/2023.acl-long.828.pdf\n",
      "https://aclanthology.org/2023.acl-long.829.pdf\n",
      "https://aclanthology.org/2023.acl-long.830.pdf\n",
      "https://aclanthology.org/2023.acl-long.831.pdf\n",
      "https://aclanthology.org/2023.acl-long.832.pdf\n",
      "https://aclanthology.org/2023.acl-long.833.pdf\n",
      "https://aclanthology.org/2023.acl-long.834.pdf\n",
      "https://aclanthology.org/2023.acl-long.835.pdf\n",
      "https://aclanthology.org/2023.acl-long.836.pdf\n",
      "https://aclanthology.org/2023.acl-long.837.pdf\n",
      "https://aclanthology.org/2023.acl-long.838.pdf\n",
      "https://aclanthology.org/2023.acl-long.839.pdf\n",
      "https://aclanthology.org/2023.acl-long.840.pdf\n",
      "https://aclanthology.org/2023.acl-long.841.pdf\n",
      "https://aclanthology.org/2023.acl-long.842.pdf\n",
      "https://aclanthology.org/2023.acl-long.843.pdf\n",
      "https://aclanthology.org/2023.acl-long.844.pdf\n",
      "https://aclanthology.org/2023.acl-long.845.pdf\n",
      "https://aclanthology.org/2023.acl-long.846.pdf\n",
      "https://aclanthology.org/2023.acl-long.847.pdf\n",
      "https://aclanthology.org/2023.acl-long.848.pdf\n",
      "https://aclanthology.org/2023.acl-long.849.pdf\n",
      "https://aclanthology.org/2023.acl-long.850.pdf\n",
      "https://aclanthology.org/2023.acl-long.851.pdf\n",
      "https://aclanthology.org/2023.acl-long.852.pdf\n",
      "https://aclanthology.org/2023.acl-long.853.pdf\n",
      "https://aclanthology.org/2023.acl-long.854.pdf\n",
      "https://aclanthology.org/2023.acl-long.855.pdf\n",
      "https://aclanthology.org/2023.acl-long.856.pdf\n",
      "https://aclanthology.org/2023.acl-long.857.pdf\n",
      "https://aclanthology.org/2023.acl-long.858.pdf\n",
      "https://aclanthology.org/2023.acl-long.859.pdf\n",
      "https://aclanthology.org/2023.acl-long.860.pdf\n",
      "https://aclanthology.org/2023.acl-long.861.pdf\n",
      "https://aclanthology.org/2023.acl-long.862.pdf\n",
      "https://aclanthology.org/2023.acl-long.863.pdf\n",
      "https://aclanthology.org/2023.acl-long.864.pdf\n",
      "https://aclanthology.org/2023.acl-long.865.pdf\n",
      "https://aclanthology.org/2023.acl-long.866.pdf\n",
      "https://aclanthology.org/2023.acl-long.867.pdf\n",
      "https://aclanthology.org/2023.acl-long.868.pdf\n",
      "https://aclanthology.org/2023.acl-long.869.pdf\n",
      "https://aclanthology.org/2023.acl-long.870.pdf\n",
      "https://aclanthology.org/2023.acl-long.871.pdf\n",
      "https://aclanthology.org/2023.acl-long.872.pdf\n",
      "https://aclanthology.org/2023.acl-long.873.pdf\n",
      "https://aclanthology.org/2023.acl-long.874.pdf\n",
      "https://aclanthology.org/2023.acl-long.875.pdf\n",
      "https://aclanthology.org/2023.acl-long.876.pdf\n",
      "https://aclanthology.org/2023.acl-long.877.pdf\n",
      "https://aclanthology.org/2023.acl-long.878.pdf\n",
      "https://aclanthology.org/2023.acl-long.879.pdf\n",
      "https://aclanthology.org/2023.acl-long.880.pdf\n",
      "https://aclanthology.org/2023.acl-long.881.pdf\n",
      "https://aclanthology.org/2023.acl-long.882.pdf\n",
      "https://aclanthology.org/2023.acl-long.883.pdf\n",
      "https://aclanthology.org/2023.acl-long.884.pdf\n",
      "https://aclanthology.org/2023.acl-long.885.pdf\n",
      "https://aclanthology.org/2023.acl-long.886.pdf\n",
      "https://aclanthology.org/2023.acl-long.887.pdf\n",
      "https://aclanthology.org/2023.acl-long.888.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://aclanthology.org/2023.acl-long.889.pdf\n",
      "https://aclanthology.org/2023.acl-long.890.pdf\n",
      "https://aclanthology.org/2023.acl-long.891.pdf\n",
      "https://aclanthology.org/2023.acl-long.892.pdf\n",
      "https://aclanthology.org/2023.acl-long.893.pdf\n",
      "https://aclanthology.org/2023.acl-long.894.pdf\n",
      "https://aclanthology.org/2023.acl-long.895.pdf\n",
      "https://aclanthology.org/2023.acl-long.896.pdf\n",
      "https://aclanthology.org/2023.acl-long.897.pdf\n",
      "https://aclanthology.org/2023.acl-long.898.pdf\n",
      "https://aclanthology.org/2023.acl-long.899.pdf\n",
      "https://aclanthology.org/2023.acl-long.900.pdf\n",
      "https://aclanthology.org/2023.acl-long.901.pdf\n",
      "https://aclanthology.org/2023.acl-long.902.pdf\n",
      "https://aclanthology.org/2023.acl-long.903.pdf\n",
      "https://aclanthology.org/2023.acl-long.904.pdf\n",
      "https://aclanthology.org/2023.acl-long.905.pdf\n",
      "https://aclanthology.org/2023.acl-long.906.pdf\n",
      "https://aclanthology.org/2023.acl-long.907.pdf\n",
      "https://aclanthology.org/2023.acl-long.908.pdf\n",
      "https://aclanthology.org/2023.acl-long.909.pdf\n",
      "https://aclanthology.org/2023.acl-long.910.pdf\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'new_columns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_24244\\3438749611.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[1;31m# Reindex the DataFrame with new columns (creates NaN values)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnew_columns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'new_columns' is not defined"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "!pip install requests PyPDF2\n",
    "\n",
    "import os\n",
    "import requests\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "\n",
    "# Fetch the webpage\n",
    "url = \"https://aclanthology.org/events/acl-2023/#2023acl-long\"\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Find all <div> elements with id \"2023acl-long\"\n",
    "div_2023acl_long = soup.find_all('div', id='2023acl-long')\n",
    "\n",
    "# Initialize lists to store names and abstracts\n",
    "names = []\n",
    "\n",
    "# Extract the data\n",
    "if div_2023acl_long:\n",
    "    for div in div_2023acl_long:\n",
    "        # Find all <p> elements with class \"d-sm-flex align-items-stretch\"\n",
    "        p_tags = div.find_all('p', class_='d-sm-flex align-items-stretch')\n",
    "        for p_tag in p_tags:\n",
    "            # Find all <span> elements with class \"d-block\"\n",
    "            span_tags = p_tag.find_all('span', class_='d-block')\n",
    "            for span_tag in span_tags:\n",
    "                # Find all <strong> elements\n",
    "                strong_tags = span_tag.find_all('strong')\n",
    "                for strong_tag in strong_tags:\n",
    "                    # Find all <a> elements with class \"align-middle\"\n",
    "                    a_tags = strong_tag.find_all('a', class_='align-middle')\n",
    "                    for a_tag in a_tags:\n",
    "                        # Extract the name from the <a> tag\n",
    "                        name = a_tag.get_text(strip=True)\n",
    "                        names.append(name)\n",
    "                        #print(name)\n",
    "                        #print(\"\\n\")\n",
    "    \n",
    "else:\n",
    "    print(\"Div with id '2023acl-long' not found on the page.\")\n",
    "    \n",
    "\n",
    "\n",
    "# Create a dictionary from the lists\n",
    "data = {'Name': names}\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data)  \n",
    "\n",
    "\n",
    "# Base URL pattern for the papers\n",
    "base_url = \"https://aclanthology.org/2023.acl-long.{}.pdf\"\n",
    "\n",
    "# Initialize an empty list to store the text of each paper\n",
    "papers_text = []\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "let us say we want papers from 1 to 6 then a = 1, b = 6\n",
    "\"\"\"\n",
    "\n",
    "a = 11\n",
    "b = 911\n",
    "\n",
    "\n",
    "\n",
    "# Function to download PDF from URL and extract text\n",
    "def extract_text_from_pdf(url):\n",
    "    # Download PDF file from URL\n",
    "    response = requests.get(url)\n",
    "    with open(\"temp_pdf.pdf\", \"wb\") as f:\n",
    "        f.write(response.content)\n",
    "\n",
    "    # Open downloaded PDF file and extract text\n",
    "    with open(\"temp_pdf.pdf\", \"rb\") as f:\n",
    "        pdf_reader = PdfReader(f)\n",
    "        num_pages = len(pdf_reader.pages)\n",
    "        text = \"\"\n",
    "        for page_num in range(num_pages):\n",
    "            page = pdf_reader.pages[page_num]\n",
    "            text += page.extract_text()\n",
    "\n",
    "    # Find the index of \"References\" and trim the text\n",
    "    index_references = text.find(\"References\")\n",
    "    text = text[:index_references]  \n",
    "\n",
    "    index_references = text.find(\"Abstract\")\n",
    "    text = text[index_references:] \n",
    "    \n",
    "    \n",
    "    # Delete temporary PDF file\n",
    "    os.remove(\"temp_pdf.pdf\")\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "# Loop through the range of papers (from 1 to 990)\n",
    "for i in range(a, b):  # Change range to (1, 911) for all papers\n",
    "    url = base_url.format(i)\n",
    "    print(url)\n",
    "    paper_text = extract_text_from_pdf(url)\n",
    "    papers_text.append(paper_text)\n",
    "\n",
    "\n",
    "# Create a dictionary from the lists\n",
    "data = {'Name': names[a+1:b+1], 'TextData': papers_text[:b] }\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "# Define a list of new column names\n",
    "#new_columns = ['Knowledge Extraction']\n",
    "\n",
    "# Reindex the DataFrame with new columns (creates NaN values)\n",
    "#df = df.reindex(columns=df.columns.tolist() + new_columns)\n",
    "\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6724b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f02d9c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "833929b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = \"The purpose of the authors: to improve dialogue systems by leveraging multiple user simulators simultaneously. The contribution of the paper: a new framework called MUST (Multi-user Simulator Training) for training task-oriented dialogue systems. MUST leverages multiple user simulators to train a dialogue system, with the goal of improving the systems robustness to various user behaviors. The method of the paper: MUST (Multi-user Simulator Training). MUST addresses the challenge of training a dialogue system on a single user simulator, which can lead to the system being over-fitted to that specific simulator and under-fitted to others. MUST accomplishes this by leveraging multiple user simulators simultaneously. The authors propose three ways to implement MUST: MUSTmerging, MUSTCRL, and MUSTuniform. MUSTadaptive is the method ultimately chosen by the authors as it tackles the challenges of balancing exploration and exploitation, and avoiding catastrophic forgetting. MUSTadaptive utilizes an adaptively-updated distribution to select user simulators during training. The dataset used in the paper: didn't find information may have used personal dataset. The findings or conclusions of the paper: that MUST leads to a more robust dialogue system that can perform well with unseen user simulators. The authors propose a framework called MUST that leverages multiple user simulators to train task-oriented dialogue systems. MUST addresses the challenges of over-fitting to specific user simulators and catastrophic forgetting by formulating the problem as a Multi-armed bandits (MAB) problem. Their method, MUSTadaptive, achieves better performance than training with a single user simulator. MUSTadaptive balances adapting to different user simulators and uniformly exploring all simulators during training. The future work of the paper: we can do advances to the model used in this paper.\"\n",
    "text2 = \"The purpose of the authors: The main challenge this paper addresses is the prevalence of unsafe behavior, such as toxic languages and harmful suggestions, in open-domain end-to-end dialogue systems, or chatbots. The contribution of the paper: The authors constructed a new dataset called SafeConv for the research of conversational safety. SafeConv provides unsafe spans in an utterance, indicating which words contribute to the detected unsafe behavior, and safe alternative responses to continue the conversation when unsafe behavior is detected. The method of the paper: The authors benchmarked three powerful models for the mitigation of conversational unsafe behavior, including a checker to detect unsafe utterances, a tagger to extract unsafe spans, and a rewriter to convert an unsafe response to a safe version. The dataset used in the paper: The dataset used in this paper is SafeConv, which is constructed by the authors for the research of conversational safety1. The findings or conclusions of the paper: The experiments showed that the detected unsafe behavior could be well explained with unsafe spans and popular chatbots could be detoxified by a huge extent. The future work of the paper: the findings suggest that there is potential for further research in explaining the emergence of unsafe behavior and detoxifying chatbots.\"\n",
    "text3 = \"The purpose of the authors: The main challenge this paper addresses is the problem of hallucinations in neural machine translation. The authors aim to alleviate this issue. The contribution of the paper: The authors propose a method that evaluates the percentage of the source contribution to a generated translation. They also show that using sentence similarity from cross-lingual embeddings further improves these results. The method of the paper: The authors use a method that evaluates the percentage of the source contribution to a generated translation. They also use sentence similarity from cross-lingual embeddings. The dataset used in the paper: The paper does not explicitly mention the dataset used. However, it can be inferred that they used a dataset of machine translations. The findings or conclusions of the paper: The method proposed by the authors improves detection accuracy for the most severe hallucinations by a factor of 2 and is able to alleviate hallucinations at test time on par with the previous best approach that relies on external models. The future work of the paper: the findings suggest that there is potential for further research in detecting and mitigating hallucinations in machine translation.\"\n",
    "text4 = \"The purpose of the authors: The main challenge this paper addresses is the issue of generating accurate and informative explanations for recommendations, especially when historical user reviews of items are often insufficient. The contribution of the paper: The authors propose a novel model, ERRA (Explainable Recommendation by personalized Review retrieval and Aspect learning), which can obtain additional information from the training sets with retrieval enhancement. They also incorporate an aspect enhancement component into their model to better capture users preferences. The method of the paper: The authors use a method that combines personalized review retrieval and aspect learning. By selecting the top-n aspects that users are most concerned about for different items, they can model user representation with more relevant details. The dataset used in the paper: The paper does not explicitly mention the dataset used. However, it can be inferred that they used a dataset of user reviews. The findings or conclusions of the paper: The experiments show that their model outperforms state-of-the-art baselines (for example, 3.4% improvement in prediction and 15.8% improvement in explanation for TripAdvisor). The future work of the paper: the findings suggest that there is potential for further research in explainable recommendation with personalized review retrieval and aspect learning.\"\n",
    "text5 = \"The purpose of the authors: The main challenge this paper addresses is the difficulties of optimizing binary and ternary neural networks, especially for transformer text generation models due to the sensitivity of the attention operation to quantization and the noise-compounding effects of autoregressive decoding in the high-cardinality output space1. The contribution of the paper: The authors demonstrate the first ternary and binary transformer models on the downstream tasks of summarization and machine translation. The method of the paper: The authors approach the problem with a mix of statistics-based quantization for the weights and elastic quantization of the activations. The dataset used in the paper: The paper does not explicitly mention the dataset used. However, it can be inferred that they used a dataset of text for summarization and machine translation. The findings or conclusions of the paper: The authors ternary BART base achieves an R1 score of 41 on the CNN/DailyMail benchmark, which is merely 3.9 points behind the full model while being 16x more efficient. Their binary model, while less accurate, achieves a highly non-trivial score of 35.6. For machine translation, they achieved BLEU scores of 21.7 and 17.6 on the WMT16 En-Ro benchmark, compared with a full precision mBART model score of 26.81. the findings suggest that there is potential for further research in binary and ternary natural language generation.\"\n",
    "text6 = \"The purpose of the authors: The main challenge this paper addresses is the limitations of prior generative and discriminative approaches in schema-guided dialogue state tracking. The authors aim to achieve better generalization and efficiency. The contribution of the paper: The authors introduce SPLAT, a novel architecture that constrains outputs to a limited prediction space, allowing for rich attention among descriptions and history while keeping computation costs constrained by incorporating linear-time attention. The method of the paper: The authors use a method that evaluates the percentage of the source contribution to a generated translation. They also use sentence similarity from cross-lingual embeddings. The dataset used in the paper: The authors demonstrate the effectiveness of their model on the Schema-Guided Dialogue (SGD) and MultiWOZ datasets. The findings or conclusions of the paper: The authors approach significantly improves upon existing models achieving 85.3 JGA on the SGD dataset. Further, they show increased robustness on the SGD-X benchmark - their model outperforms the more than 30x larger D3ST-XXL model by 5.0 points. The future work of the paper: the findings suggest that there is potential for further research in schema-guided dialogue state tracking.\"\n",
    "text7 = \"The purpose of the authors: The main challenge this paper addresses is the gap for multi-party dialogues in dialogue response generation. Unlike two-party dialogues where each response is a direct reply to its previous utterance, the addressee of a response utterance should be specified before it is generated in the multi-party scenario. The contribution of the paper: The authors propose an Expectation-Maximization (EM) approach that iteratively performs the expectation steps to generate addressee labels, and the maximization steps to optimize a response generation model. The method of the paper: The authors use an Expectation-Maximization (EM) approach that iteratively performs the expectation steps to generate addressee labels, and the maximization steps to optimize a response generation model. The dataset used in the paper: The paper does not explicitly mention the dataset used. However, it can be inferred that they used a dataset of multi-party dialogues. The findings or conclusions of the paper: Theoretical analyses and extensive experiments have justified the feasibility and effectiveness of the proposed method. The future work of the paper: the findings suggest that there is potential for further research in multi-party dialogue response generation.\"\n",
    "text8 = \"The purpose of the authors: The main challenge this paper addresses is the task of detecting linguistically complex named entities in low-context text. The authors aim to address the data scarcity problem in low-resource complex Named Entity Recognition (NER). The contribution of the paper: The authors present ACLM (Attention-map aware keyword selection for Conditional Language Model fine-tuning), a novel data augmentation approach based on conditional generation. The method of the paper: ACLM builds on BART and is optimized on a novel text reconstruction or denoising task - they use selective masking (aided by attention maps) to retain the named entities and certain keywords in the input sentence that provide contextually relevant additional knowledge or hints about the named entities. The dataset used in the paper: The paper does not explicitly mention the dataset used. However, it can be inferred that they used a dataset of complex named entities. The findings or conclusions of the paper: The authors demonstrate the effectiveness of ACLM both qualitatively and quantitatively on monolingual, cross-lingual, and multilingual complex NER across various low-resource settings. ACLM outperforms all their neural baselines by a significant margin (1%-36%). In addition, they demonstrate the application of ACLM to other domains that suffer from data scarcity (e.g., biomedical). In practice, ACLM generates more effective and factual augmentations for these domains than prior methods. The future work of the paper: The findings suggest that there is potential for further research in generative data augmentation for low-resource complex NER.\"\n",
    "text9 = \"The purpose of the authors: The main challenge this paper addresses is the performance of AI pair programmers that automatically synthesize programs for data wrangling and analytic tasks given natural language (NL) intents from users. The contribution of the paper: The authors build ARCADE, a benchmark of 1,078 code generation problems using the pandas data analysis framework in data science notebooks. ARCADE features multiple rounds of NL-to-code problems from the same notebook. The method of the paper: To establish a strong baseline on this challenging task, the authors develop PaChiNCo, a 62B code language model (LM) for Python computational notebooks, which significantly outperforms public code LMs. The dataset used in the paper: The dataset used in this paper is ARCADE, which is a benchmark of 1,078 code generation problems using the pandas data analysis framework in data science notebooks. The findings or conclusions of the paper: The authors explore few-shot prompting strategies to elicit better code with step-by-step decomposition and NL explanation, showing the potential to improve the diversity and explainability of model predictions. The future work of the paper: The findings suggest that there is potential for further research in natural language to code generation in interactive data science notebooks.\"\n",
    "text10 = \"The purpose of the authors: The main challenge this paper addresses is the time-consuming decoding in k-nearest-neighbor machine translation (kNN-MT). The authors aim to improve the decoding speed of kNN-MT. The contribution of the paper: The authors propose Subset kNN-MT, which improves the decoding speed of kNN-MT by two methods: (1) retrieving neighbor target tokens from a subset that is the set of neighbor sentences of the input sentence, not from all sentences, and (2) efficient distance computation technique that is suitable for subset neighbor search using a look-up table. The method of the paper: The authors use a method that retrieves neighbor target tokens from a subset that is the set of neighbor sentences of the input sentence, not from all sentences. They also use an efficient distance computation technique that is suitable for subset neighbor search using a look-up table. The dataset used in the paper: The paper does not explicitly mention the dataset used. However, it can be inferred that they used a dataset of machine translations. The findings or conclusions of the paper: The authors proposed method achieved a speed-up of up to 132.2 times and an improvement in BLEU score of up to 1.6 compared with kNN-MT in the WMT19 De-En translation task and the domain adaptation tasks in De-En and En-Ja. The future work of the paper: The findings suggest that there is potential for further research in nearest neighbor machine translation.\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df.at[0, 'Knowledge Extraction'] = text1\n",
    "df.at[1, 'Knowledge Extraction'] = text2 \n",
    "df.at[2, 'Knowledge Extraction'] = text3\n",
    "df.at[3, 'Knowledge Extraction'] = text4 \n",
    "df.at[4, 'Knowledge Extraction'] = text5\n",
    "df.at[5, 'Knowledge Extraction'] = text6 \n",
    "df.at[6, 'Knowledge Extraction'] = text7\n",
    "df.at[7, 'Knowledge Extraction'] = text8 \n",
    "df.at[8, 'Knowledge Extraction'] = text9\n",
    "df.at[9, 'Knowledge Extraction'] = text10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0810764",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a64f3fd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>TextData</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MIL-Decoding: Detoxifying Language Models at T...</td>\n",
       "      <td>Abstract Despite advances in large pretrained ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dependency resolution at the syntax-semantics ...</td>\n",
       "      <td>Abstract Using psycholinguistic and computatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Open-ended Long Text Generation via Masked Lan...</td>\n",
       "      <td>Abstract Pretrained autoregressive (AR) langua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A Method for Studying Semantic Construal in Gr...</td>\n",
       "      <td>Abstract We study semantic construal in gramma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HolographicCCGParsing</td>\n",
       "      <td>Abstract We propose a method for formulating C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>MeetingBank: A Benchmark Dataset for Meeting S...</td>\n",
       "      <td>Abstract As the number of recorded meetings in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>UniEX: An Effective and Efficient Framework fo...</td>\n",
       "      <td>Abstract We propose a new paradigm for univers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>DEplain: AGerman Parallel Corpus with Intralin...</td>\n",
       "      <td>Abstract Text simplification is an intralingua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>A Neural Divide-and-Conquer Reasoning Framewor...</td>\n",
       "      <td>Abstract Pretrained VisionLanguage Models (VLM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>RARR: Researching and Revising What Language M...</td>\n",
       "      <td>Abstract Language models (LMs) now excel at ma...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>900 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Name  \\\n",
       "0    MIL-Decoding: Detoxifying Language Models at T...   \n",
       "1    Dependency resolution at the syntax-semantics ...   \n",
       "2    Open-ended Long Text Generation via Masked Lan...   \n",
       "3    A Method for Studying Semantic Construal in Gr...   \n",
       "4                                HolographicCCGParsing   \n",
       "..                                                 ...   \n",
       "895  MeetingBank: A Benchmark Dataset for Meeting S...   \n",
       "896  UniEX: An Effective and Efficient Framework fo...   \n",
       "897  DEplain: AGerman Parallel Corpus with Intralin...   \n",
       "898  A Neural Divide-and-Conquer Reasoning Framewor...   \n",
       "899  RARR: Researching and Revising What Language M...   \n",
       "\n",
       "                                              TextData  \n",
       "0    Abstract Despite advances in large pretrained ...  \n",
       "1    Abstract Using psycholinguistic and computatio...  \n",
       "2    Abstract Pretrained autoregressive (AR) langua...  \n",
       "3    Abstract We study semantic construal in gramma...  \n",
       "4    Abstract We propose a method for formulating C...  \n",
       "..                                                 ...  \n",
       "895  Abstract As the number of recorded meetings in...  \n",
       "896  Abstract We propose a new paradigm for univers...  \n",
       "897  Abstract Text simplification is an intralingua...  \n",
       "898  Abstract Pretrained VisionLanguage Models (VLM...  \n",
       "899  Abstract Language models (LMs) now excel at ma...  \n",
       "\n",
       "[900 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def clean_and_join_text(text):\n",
    "    # Join all lines into a single paragraph\n",
    "    joined_text = ' '.join(text.split('\\n'))\n",
    "    \n",
    "    # Replace consecutive spaces with a single space\n",
    "    cleaned_text = ' '.join(joined_text.split())\n",
    "    \n",
    "    # Correct hyphenated words that were split due to line breaks\n",
    "    cleaned_text = re.sub(r'(\\w+)\\-\\s*(\\w+)', r'\\1\\2', cleaned_text)\n",
    "    \n",
    "    return cleaned_text\n",
    "\n",
    "# Assuming df is your dataframe and 'TextData' is the column containing the text\n",
    "df['TextData'] = df['TextData'].apply(clean_and_join_text)\n",
    "\n",
    "# Display the cleaned and joined text\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "348b717b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to Test_data.json\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming df is your DataFrame containing the data you want to save\n",
    "\n",
    "# Function to clean problematic characters\n",
    "def clean_text(text):\n",
    "    try:\n",
    "        # Encode text to handle surrogate characters\n",
    "        cleaned_text = text.encode('utf-8', errors='ignore').decode('utf-8')\n",
    "        return cleaned_text\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# Apply clean_text function to all columns of DataFrame\n",
    "df_cleaned = df.applymap(clean_text)\n",
    "\n",
    "# Export cleaned DataFrame to JSON\n",
    "json_file_path = 'Test_data.json'\n",
    "df_cleaned.to_json(json_file_path, orient='records', force_ascii=False)\n",
    "print(f\"Data saved to {json_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46493df4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to C:\\Users\\harsh\\Downloads\\Test_data.json\n"
     ]
    }
   ],
   "source": [
    "# Specify the file path for saving the JSON file locally\n",
    "json_file_path = r'C:\\Users\\harsh\\Downloads\\Test_data.json'\n",
    "\n",
    "# Export cleaned DataFrame to JSON with specified file path\n",
    "df_cleaned.to_json(json_file_path, orient='records', force_ascii=False)\n",
    "\n",
    "print(f\"Data saved to {json_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f08b092",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9a4ad9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "\n",
    "\n",
    "# Convert DataFrame to Hugging Face dataset\n",
    "dataset = Dataset.from_pandas(df)\n",
    "#dataset = dataset.train_test_split(test_size=0.3)  # Splitting the dataset for training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2fd3b816",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ee09e6e13034757b586dcf67c5c828a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdd5f95f5c1e4c8ebb94177063ee6425",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Split the dataset\n",
    "split_dataset = dataset.train_test_split(test_size=0.1)\n",
    "\n",
    "# Define tokenizer and model\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "\n",
    "# Add a PAD token if not present\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "    model.resize_token_embeddings(len(tokenizer))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1df202cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10ee117d1dfc46a2aa007373a0352a66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7151c4ad33c24ace8bc51fbf56c97960",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15/15 18:17, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>74.981369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>49.125809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>40.283733</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=15, training_loss=47.848291015625, metrics={'train_runtime': 1160.1587, 'train_samples_per_second': 0.023, 'train_steps_per_second': 0.013, 'total_flos': 7054884864000.0, 'train_loss': 47.848291015625, 'epoch': 3.0})"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize_and_prepare_labels(examples):\n",
    "    # Encode the inputs\n",
    "    inputs = tokenizer(examples['TextData'], max_length=512, truncation=True, padding=\"max_length\", return_tensors=\"pt\")\n",
    "    # Create labels by shifting the input ids to the right by one\n",
    "    labels = inputs.input_ids.clone()\n",
    "    labels[:, :-1] = labels[:, 1:].clone()\n",
    "    labels[:, -1] = -100  # We use -100 to mask the loss to ignore the input token in the loss computation\n",
    "\n",
    "    return {'input_ids': inputs.input_ids, 'attention_mask': inputs.attention_mask, 'labels': labels}\n",
    "\n",
    "# Apply tokenization and label preparation\n",
    "tokenized_datasets = {split: split_dataset[split].map(tokenize_and_prepare_labels, batched=True) for split in split_dataset.keys()}\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets['train'],\n",
    "    eval_dataset=tokenized_datasets['test']\n",
    ")\n",
    "\n",
    "# Start training\n",
    "trainer.train()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c72c4567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\harsh\\anaconda3\\lib\\site-packages (2.28.1)\n",
      "Requirement already satisfied: PyPDF2 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (3.0.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from requests) (2022.9.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from requests) (1.26.18)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from requests) (3.3)\n",
      "Requirement already satisfied: typing_extensions>=3.10.0.0 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from PyPDF2) (4.10.0)\n",
      "https://aclanthology.org/2023.acl-long.11.pdf\n",
      "https://aclanthology.org/2023.acl-long.12.pdf\n",
      "https://aclanthology.org/2023.acl-long.13.pdf\n",
      "https://aclanthology.org/2023.acl-long.14.pdf\n",
      "https://aclanthology.org/2023.acl-long.15.pdf\n",
      "https://aclanthology.org/2023.acl-long.16.pdf\n",
      "https://aclanthology.org/2023.acl-long.17.pdf\n",
      "https://aclanthology.org/2023.acl-long.18.pdf\n",
      "https://aclanthology.org/2023.acl-long.19.pdf\n",
      "https://aclanthology.org/2023.acl-long.20.pdf\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>TextData</th>\n",
       "      <th>Knowledge Extraction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MIL-Decoding: Detoxifying Language Models at T...</td>\n",
       "      <td>Abstract Despite advances in large pretrained ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dependency resolution at the syntax-semantics ...</td>\n",
       "      <td>Abstract Using psycholinguistic and computatio...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Open-ended Long Text Generation via Masked Lan...</td>\n",
       "      <td>Abstract Pretrained autoregressive (AR) langua...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A Method for Studying Semantic Construal in Gr...</td>\n",
       "      <td>Abstract We study semantic construal in gramma...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HolographicCCGParsing</td>\n",
       "      <td>Abstract We propose a method for formulating C...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Prompts Can Play Lottery Tickets Well: Achievi...</td>\n",
       "      <td>Abstract Thanks to the recent success of Pretr...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Retrieve-and-Sample: Document-level Event Argu...</td>\n",
       "      <td>Abstract Recent studies have shown the effecti...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>WeCheck: Strong Factual Consistency Checker vi...</td>\n",
       "      <td>Abstract A crucial issue of current text gener...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AMR-based Network for Aspect-based Sentiment A...</td>\n",
       "      <td>Abstract Aspectbased sentiment analysis (ABSA)...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Text Adversarial Purification as Defense again...</td>\n",
       "      <td>Abstract Adversarial purification is a success...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Name  \\\n",
       "0  MIL-Decoding: Detoxifying Language Models at T...   \n",
       "1  Dependency resolution at the syntax-semantics ...   \n",
       "2  Open-ended Long Text Generation via Masked Lan...   \n",
       "3  A Method for Studying Semantic Construal in Gr...   \n",
       "4                              HolographicCCGParsing   \n",
       "5  Prompts Can Play Lottery Tickets Well: Achievi...   \n",
       "6  Retrieve-and-Sample: Document-level Event Argu...   \n",
       "7  WeCheck: Strong Factual Consistency Checker vi...   \n",
       "8  AMR-based Network for Aspect-based Sentiment A...   \n",
       "9  Text Adversarial Purification as Defense again...   \n",
       "\n",
       "                                            TextData  Knowledge Extraction  \n",
       "0  Abstract Despite advances in large pretrained ...                   NaN  \n",
       "1  Abstract Using psycholinguistic and computatio...                   NaN  \n",
       "2  Abstract Pretrained autoregressive (AR) langua...                   NaN  \n",
       "3  Abstract We study semantic construal in gramma...                   NaN  \n",
       "4  Abstract We propose a method for formulating C...                   NaN  \n",
       "5  Abstract Thanks to the recent success of Pretr...                   NaN  \n",
       "6  Abstract Recent studies have shown the effecti...                   NaN  \n",
       "7  Abstract A crucial issue of current text gener...                   NaN  \n",
       "8  Abstract Aspectbased sentiment analysis (ABSA)...                   NaN  \n",
       "9  Abstract Adversarial purification is a success...                   NaN  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "!pip install requests PyPDF2\n",
    "\n",
    "import os\n",
    "import requests\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "\n",
    "# Fetch the webpage\n",
    "url = \"https://aclanthology.org/events/acl-2023/#2023acl-long\"\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Find all <div> elements with id \"2023acl-long\"\n",
    "div_2023acl_long = soup.find_all('div', id='2023acl-long')\n",
    "\n",
    "# Initialize lists to store names and abstracts\n",
    "names = []\n",
    "\n",
    "# Extract the data\n",
    "if div_2023acl_long:\n",
    "    for div in div_2023acl_long:\n",
    "        # Find all <p> elements with class \"d-sm-flex align-items-stretch\"\n",
    "        p_tags = div.find_all('p', class_='d-sm-flex align-items-stretch')\n",
    "        for p_tag in p_tags:\n",
    "            # Find all <span> elements with class \"d-block\"\n",
    "            span_tags = p_tag.find_all('span', class_='d-block')\n",
    "            for span_tag in span_tags:\n",
    "                # Find all <strong> elements\n",
    "                strong_tags = span_tag.find_all('strong')\n",
    "                for strong_tag in strong_tags:\n",
    "                    # Find all <a> elements with class \"align-middle\"\n",
    "                    a_tags = strong_tag.find_all('a', class_='align-middle')\n",
    "                    for a_tag in a_tags:\n",
    "                        # Extract the name from the <a> tag\n",
    "                        name = a_tag.get_text(strip=True)\n",
    "                        names.append(name)\n",
    "                        #print(name)\n",
    "                        #print(\"\\n\")\n",
    "    \n",
    "else:\n",
    "    print(\"Div with id '2023acl-long' not found on the page.\")\n",
    "    \n",
    "\n",
    "\n",
    "# Create a dictionary from the lists\n",
    "data = {'Name': names}\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data)  \n",
    "\n",
    "\n",
    "# Base URL pattern for the papers\n",
    "base_url = \"https://aclanthology.org/2023.acl-long.{}.pdf\"\n",
    "\n",
    "# Initialize an empty list to store the text of each paper\n",
    "papers_text = []\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "let us say we want papers from 1 to 6 then a = 1, b = 6\n",
    "\"\"\"\n",
    "\n",
    "a = 11\n",
    "b = 21\n",
    "\n",
    "\n",
    "\n",
    "# Function to download PDF from URL and extract text\n",
    "def extract_text_from_pdf(url):\n",
    "    # Download PDF file from URL\n",
    "    response = requests.get(url)\n",
    "    with open(\"temp_pdf.pdf\", \"wb\") as f:\n",
    "        f.write(response.content)\n",
    "\n",
    "    # Open downloaded PDF file and extract text\n",
    "    with open(\"temp_pdf.pdf\", \"rb\") as f:\n",
    "        pdf_reader = PdfReader(f)\n",
    "        num_pages = len(pdf_reader.pages)\n",
    "        text = \"\"\n",
    "        for page_num in range(num_pages):\n",
    "            page = pdf_reader.pages[page_num]\n",
    "            text += page.extract_text()\n",
    "\n",
    "    # Find the index of \"References\" and trim the text\n",
    "    index_references = text.find(\"References\")\n",
    "    text = text[:index_references]  \n",
    "\n",
    "    index_references = text.find(\"Abstract\")\n",
    "    text = text[index_references:] \n",
    "    \n",
    "    \n",
    "    # Delete temporary PDF file\n",
    "    os.remove(\"temp_pdf.pdf\")\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "# Loop through the range of papers (from 1 to 990)\n",
    "for i in range(a, b):  # Change range to (1, 911) for all papers\n",
    "    url = base_url.format(i)\n",
    "    print(url)\n",
    "    paper_text = extract_text_from_pdf(url)\n",
    "    papers_text.append(paper_text)\n",
    "\n",
    "\n",
    "# Create a dictionary from the lists\n",
    "data = {'Name': names[a+1:b+1], 'TextData': papers_text[:b] }\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "# Define a list of new column names\n",
    "new_columns = ['Knowledge Extraction']\n",
    "\n",
    "# Reindex the DataFrame with new columns (creates NaN values)\n",
    "df = df.reindex(columns=df.columns.tolist() + new_columns)\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def clean_and_join_text(text):\n",
    "    # Join all lines into a single paragraph\n",
    "    joined_text = ' '.join(text.split('\\n'))\n",
    "    \n",
    "    # Replace consecutive spaces with a single space\n",
    "    cleaned_text = ' '.join(joined_text.split())\n",
    "    \n",
    "    # Correct hyphenated words that were split due to line breaks\n",
    "    cleaned_text = re.sub(r'(\\w+)\\-\\s*(\\w+)', r'\\1\\2', cleaned_text)\n",
    "    \n",
    "    return cleaned_text\n",
    "\n",
    "# Assuming df is your dataframe and 'TextData' is the column containing the text\n",
    "df['TextData'] = df['TextData'].apply(clean_and_join_text)\n",
    "\n",
    "# Display the cleaned and joined text\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3986c6cb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "`max_new_tokens` must be greater than 0, but is 0.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_32328\\1014162169.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[0mnew_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnew_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerate_knowledge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_32328\\1014162169.py\u001b[0m in \u001b[0;36mgenerate_knowledge\u001b[1;34m(input_text)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;31m# Generate outputs using the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_new_tokens\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_new_tokens\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_return_sequences\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;31m# Decode the generated tokens to a string\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 115\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    116\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\generation\\utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[1;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[0;32m   1322\u001b[0m         \u001b[1;31m# 1. Handle `generation_config` and kwargs that might update it, and validate the `.generate()` call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1323\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_model_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1324\u001b[1;33m         \u001b[0mgeneration_config\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_kwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_prepare_generation_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgeneration_config\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1325\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_model_kwargs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1326\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\generation\\utils.py\u001b[0m in \u001b[0;36m_prepare_generation_config\u001b[1;34m(self, generation_config, **kwargs)\u001b[0m\n\u001b[0;32m   1218\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1219\u001b[0m             \u001b[0mgeneration_config\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgeneration_config\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1220\u001b[1;33m             \u001b[0mmodel_kwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgeneration_config\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1221\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1222\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mgeneration_config\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_kwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\generation\\configuration_utils.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m   1086\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1087\u001b[0m         \u001b[1;31m# Confirm that the updated instance is still valid\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1088\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1089\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1090\u001b[0m         \u001b[1;31m# Remove all the attributes that were updated, without modifying the input dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\generation\\configuration_utils.py\u001b[0m in \u001b[0;36mvalidate\u001b[1;34m(self, is_init)\u001b[0m\n\u001b[0;32m    472\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"`early_stopping` must be a boolean or 'never', but is {self.early_stopping}.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    473\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_new_tokens\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_new_tokens\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 474\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"`max_new_tokens` must be greater than 0, but is {self.max_new_tokens}.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    475\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m         \u001b[1;31m# Validation of attribute relations:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: `max_new_tokens` must be greater than 0, but is 0."
     ]
    }
   ],
   "source": [
    "new_data = [df.iloc[0,1],df.iloc[0,2]]\n",
    "\n",
    "\n",
    "def generate_knowledge(input_text):\n",
    "    inputs = tokenizer(input_text, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "    outputs = model.generate(**inputs, max_length=150, num_return_sequences=1)\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# Example usage\n",
    "\n",
    "\n",
    "for text in new_data:\n",
    "    print(generate_knowledge(text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5429abd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>TextData</th>\n",
       "      <th>Purospe</th>\n",
       "      <th>Contribution</th>\n",
       "      <th>Method</th>\n",
       "      <th>DataSet</th>\n",
       "      <th>Conclusion</th>\n",
       "      <th>Future work</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Introduction</th>\n",
       "      <th>Limitations</th>\n",
       "      <th>PurposeText</th>\n",
       "      <th>all</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One Cannot Stand for Everyone! Leveraging Mult...</td>\n",
       "      <td>Abstract User simulators are agents designed t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Conclusion In this paper, we propose a framewo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Abstract User simulators are agents designed t...</td>\n",
       "      <td>Introduction Taskoriented dialogue systems aim...</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>Abstract User simulators are agents designed t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SafeConv: Explaining and Correcting Conversati...</td>\n",
       "      <td>Abstract One of the main challenges opendomain...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Conclusion In this paper, we study how to expl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Abstract One of the main challenges opendomain...</td>\n",
       "      <td>Introduction Safety of artificial intelligence...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1 Introduction Safety of artificial intelligen...</td>\n",
       "      <td>Abstract One of the main challenges opendomain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Detecting and Mitigating Hallucinations in Mac...</td>\n",
       "      <td>Abstract While the problem of hallucinations i...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Conclusions We start by asking how far we can ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Abstract While the problem of hallucinations i...</td>\n",
       "      <td>Introduction Hallucinations in machine transla...</td>\n",
       "      <td>Limitations Our analysis and conclusions have ...</td>\n",
       "      <td></td>\n",
       "      <td>Abstract While the problem of hallucinations i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Explainable Recommendation with Personalized R...</td>\n",
       "      <td>Abstract Explainable recommendation is a techn...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Conclusion In this paper, we propose a novel m...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Abstract Explainable recommendation is a techn...</td>\n",
       "      <td>Introduction Recent years have witnessed a gro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>Abstract Explainable recommendation is a techn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Binary and Ternary Natural Language Generation</td>\n",
       "      <td>Abstract Ternary and binary neural networks en...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Conclusion We have demonstrated high accuracy ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Abstract Ternary and binary neural networks en...</td>\n",
       "      <td>Introduction Generative pretrained transformer...</td>\n",
       "      <td>Limitations We conduct experiments on public d...</td>\n",
       "      <td>1 Introduction Generative pretrained transform...</td>\n",
       "      <td>Abstract Ternary and binary neural networks en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Span-Selective Linear Attention Transformers f...</td>\n",
       "      <td>Abstract In schemaguided dialogue state tracki...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Conclusion In this work we introduced SPLAT, a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Abstract In schemaguided dialogue state tracki...</td>\n",
       "      <td>Introduction Dialogue State Tracking (DST) ref...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1 Introduction Dialogue State Tracking (DST) r...</td>\n",
       "      <td>Abstract In schemaguided dialogue state tracki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>EMPre-training for Multi-party Dialogue Respon...</td>\n",
       "      <td>Abstract Dialogue response generation requires...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Abstract Dialogue response generation requires...</td>\n",
       "      <td>Introduction Inspired by the tremendous succes...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1 Introduction Inspired by the tremendous succ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ACLM: A Selective-Denoising based Generative D...</td>\n",
       "      <td>Abstract Complex Named Entity Recognition (NER...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Conclusion In this paper, we propose ACLM, a n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Abstract Complex Named Entity Recognition (NER...</td>\n",
       "      <td>Introduction Named Entity Recognition (NER) is...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>In practice, ACLM generates more effective and...</td>\n",
       "      <td>Abstract Complex Named Entity Recognition (NER...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Natural Language to Code Generation in Interac...</td>\n",
       "      <td>Abstract Computational notebooks, such as Jupy...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Conclusion In this paper we present ARCADE , a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Abstract Computational notebooks, such as Jupy...</td>\n",
       "      <td>Introduction Data science is the process of ex...</td>\n",
       "      <td>Limitations We discuss limitations of our work...</td>\n",
       "      <td>1 Introduction Data science is the process of ...</td>\n",
       "      <td>Abstract Computational notebooks, such as Jupy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Subset Retrieval Nearest Neighbor Machine Tran...</td>\n",
       "      <td>Abstract knearest-neighbor machine translation...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Conclusion In this paper, we proposed Subset ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Abstract knearest-neighbor machine translation...</td>\n",
       "      <td>Introduction Neural machine translation (NMT) ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>Abstract knearest-neighbor machine translation...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Name  \\\n",
       "0  One Cannot Stand for Everyone! Leveraging Mult...   \n",
       "1  SafeConv: Explaining and Correcting Conversati...   \n",
       "2  Detecting and Mitigating Hallucinations in Mac...   \n",
       "3  Explainable Recommendation with Personalized R...   \n",
       "4     Binary and Ternary Natural Language Generation   \n",
       "5  Span-Selective Linear Attention Transformers f...   \n",
       "6  EMPre-training for Multi-party Dialogue Respon...   \n",
       "7  ACLM: A Selective-Denoising based Generative D...   \n",
       "8  Natural Language to Code Generation in Interac...   \n",
       "9  Subset Retrieval Nearest Neighbor Machine Tran...   \n",
       "\n",
       "                                            TextData  Purospe  Contribution  \\\n",
       "0  Abstract User simulators are agents designed t...      NaN           NaN   \n",
       "1  Abstract One of the main challenges opendomain...      NaN           NaN   \n",
       "2  Abstract While the problem of hallucinations i...      NaN           NaN   \n",
       "3  Abstract Explainable recommendation is a techn...      NaN           NaN   \n",
       "4  Abstract Ternary and binary neural networks en...      NaN           NaN   \n",
       "5  Abstract In schemaguided dialogue state tracki...      NaN           NaN   \n",
       "6  Abstract Dialogue response generation requires...      NaN           NaN   \n",
       "7  Abstract Complex Named Entity Recognition (NER...      NaN           NaN   \n",
       "8  Abstract Computational notebooks, such as Jupy...      NaN           NaN   \n",
       "9  Abstract knearest-neighbor machine translation...      NaN           NaN   \n",
       "\n",
       "   Method  DataSet                                         Conclusion  \\\n",
       "0     NaN      NaN  Conclusion In this paper, we propose a framewo...   \n",
       "1     NaN      NaN  Conclusion In this paper, we study how to expl...   \n",
       "2     NaN      NaN  Conclusions We start by asking how far we can ...   \n",
       "3     NaN      NaN  Conclusion In this paper, we propose a novel m...   \n",
       "4     NaN      NaN  Conclusion We have demonstrated high accuracy ...   \n",
       "5     NaN      NaN  Conclusion In this work we introduced SPLAT, a...   \n",
       "6     NaN      NaN                                                NaN   \n",
       "7     NaN      NaN  Conclusion In this paper, we propose ACLM, a n...   \n",
       "8     NaN      NaN  Conclusion In this paper we present ARCADE , a...   \n",
       "9     NaN      NaN  Conclusion In this paper, we proposed Subset ...   \n",
       "\n",
       "   Future work                                           Abstract  \\\n",
       "0          NaN  Abstract User simulators are agents designed t...   \n",
       "1          NaN  Abstract One of the main challenges opendomain...   \n",
       "2          NaN  Abstract While the problem of hallucinations i...   \n",
       "3          NaN  Abstract Explainable recommendation is a techn...   \n",
       "4          NaN  Abstract Ternary and binary neural networks en...   \n",
       "5          NaN  Abstract In schemaguided dialogue state tracki...   \n",
       "6          NaN  Abstract Dialogue response generation requires...   \n",
       "7          NaN  Abstract Complex Named Entity Recognition (NER...   \n",
       "8          NaN  Abstract Computational notebooks, such as Jupy...   \n",
       "9          NaN  Abstract knearest-neighbor machine translation...   \n",
       "\n",
       "                                        Introduction  \\\n",
       "0  Introduction Taskoriented dialogue systems aim...   \n",
       "1  Introduction Safety of artificial intelligence...   \n",
       "2  Introduction Hallucinations in machine transla...   \n",
       "3  Introduction Recent years have witnessed a gro...   \n",
       "4  Introduction Generative pretrained transformer...   \n",
       "5  Introduction Dialogue State Tracking (DST) ref...   \n",
       "6  Introduction Inspired by the tremendous succes...   \n",
       "7  Introduction Named Entity Recognition (NER) is...   \n",
       "8  Introduction Data science is the process of ex...   \n",
       "9  Introduction Neural machine translation (NMT) ...   \n",
       "\n",
       "                                         Limitations  \\\n",
       "0                                                NaN   \n",
       "1                                                NaN   \n",
       "2  Limitations Our analysis and conclusions have ...   \n",
       "3                                                NaN   \n",
       "4  Limitations We conduct experiments on public d...   \n",
       "5                                                NaN   \n",
       "6                                                NaN   \n",
       "7                                                NaN   \n",
       "8  Limitations We discuss limitations of our work...   \n",
       "9                                                NaN   \n",
       "\n",
       "                                         PurposeText  \\\n",
       "0                                                      \n",
       "1  1 Introduction Safety of artificial intelligen...   \n",
       "2                                                      \n",
       "3                                                      \n",
       "4  1 Introduction Generative pretrained transform...   \n",
       "5  1 Introduction Dialogue State Tracking (DST) r...   \n",
       "6  1 Introduction Inspired by the tremendous succ...   \n",
       "7  In practice, ACLM generates more effective and...   \n",
       "8  1 Introduction Data science is the process of ...   \n",
       "9                                                      \n",
       "\n",
       "                                                 all  \n",
       "0  Abstract User simulators are agents designed t...  \n",
       "1  Abstract One of the main challenges opendomain...  \n",
       "2  Abstract While the problem of hallucinations i...  \n",
       "3  Abstract Explainable recommendation is a techn...  \n",
       "4  Abstract Ternary and binary neural networks en...  \n",
       "5  Abstract In schemaguided dialogue state tracki...  \n",
       "6                                                NaN  \n",
       "7  Abstract Complex Named Entity Recognition (NER...  \n",
       "8  Abstract Computational notebooks, such as Jupy...  \n",
       "9  Abstract knearest-neighbor machine translation...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4442446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Abstract User simulators are agents designed to imitate human users; recent advances have found that Taskoriented Dialogue (ToD) systems optimized toward a user simulator could better satisfy the need of human users. However, this might result in a suboptimal ToD system if it is tailored to only one ad hoc user simulator, since human users can behave differently. In this paper, we propose a framework called MUST1to optimize ToD systems via leveraging Multiple UserSimula Tors. The main challenges of implementing the MUST are 1) how to adaptively determine which user simulator to interact with the ToD system at each optimization step, since the ToD system might be overfitted to some specific user simulators, and simultaneously underfitted to some others; 2) how to avoid catastrophic forgetting of the adaption for a simulator that is not selected for several consecutive optimization steps. To tackle these challenges, we formulate MUST as a Multiarmed bandits (MAB) problem and provide a method called MUST adaptive that balances i) the boosting adaption for adaptive interactions between different user simulators and the ToD system andii) the uniform adaption to avoid the catastrophic forgetting issue. With both automatic evaluations and human evaluations, our experimental results on MultiWOZ show that the dialogue system trained by MUST achieves a better performance than those trained by a single user simulator. It also has a better generalization ability when testing with unseen user simulators. 1 Introduction Taskoriented dialogue systems aim to help users accomplish their various tasks (e.g., restaurant reservations) through natural language conversations. Training taskoriented dialogue systems in 1The code is available at https://github.com/ kiseliu/must .supervised learning approaches often requires a large amount of expertlabeled dialogues, however collecting these dialogues is usually expensive and timeconsuming. Moreover, even with a large amount of dialogue data, some dialogue states may not be explored sufficiently for dialogue systems2 (Li et al., 2016b). To this end, many researchers try to build user simulators to mimic human users for generating reasonable and natural conversations. By using a user simulator and sampling user goals, we can train the dialogue system from scratch with reinforcement learning (RL) algorithms. Previous works tend to design better user simulator models (Schatzmann et al., 2007; Asri et al., 2016; Gur et al., 2018; Kreyssig et al., 2018; Lin et al., 2021). Especially, Shi et al. (2019) builds various user simulators and analyzes the behavior of each user simulator in the popular restaurant search task from MultiWOZ (Budzianowski et al., 2018). In real scenarios, dialogue systems need to face various types of users. A single ad hoc user simulator can only represent one or a group of users, while other users might be underrepresented. Instead of choosing the bestperforming one from many dialogue systems trained by different single user simulators, we believe that it is worth trying to train a dialogue system by leveraging all user simulators simultaneously. In this paper, we propose a framework called MUST to utilize Multiple UserSimula Tors simultaneously to obtain a better system agent. There exist several simple ways to implement the MUST framework, including a merging strategy, a continual reinforcement learning (CRL) strategy, and a uniform adaption strategy, namely MUST merging , MUST CRL, and MUST uniform respectively (See 3.2). However, none of them could effectively tackle the challenges: 1) how to efficiently leverage multiple user simulators to train the dialogue 2We use the dialogue systems to refer to the taskoriented dialogue systems for simplicity in this paper.1system since the system might be easily overfitted to some specific user simulators and simultaneously underfitted to some others, and 2) it should avoid a catastrophic forgetting issue. To tackle them effectively, we first formulate the problem as a Multiarmed bandits (MAB) problem (Auer et al., 2002); similar to the exploitation vs exploration tradeoff, specifying multiple user simulators should trade off a boosting adaption (tackling challenge 1) and a uniform adaption (tackling challenge 2), see 4.1 for more details. Then we implement a new method called MUST adaptive to utilize an adaptivelyupdated distribution among all user simulators to sample them when training the dialogue system in the RL training. Our contributions are threefold: (1) To the best of our knowledge, our proposed MUST is the first developed work to improve the dialogue system by using multiple user simulators simultaneously; (2) We design several ways to implement the MUST. Especially, we formulate MUST as a Multiarmed bandits (MAB) problem, based on which we provide a novel method MUST adaptive ; and (3) The results show that dialogue systems trained with MUST consistently outperform those trained with a single user simulator through automatic and human evaluations, showing its potential for robustness to the diversity of user simulators. Importantly, it significantly improves the performance of the dialogue system tested on outof-domain evaluation. Moreover, our results show that our method MUST adaptive can efficiently leverage multiple user simulators to train the dialogue system in terms of convergence speed. 2 Background Dialogue system. Taskoriented dialogue systems aim to help users accomplish various tasks such as restaurant reservations through natural language conversations. Researchers usually divide the taskoriented dialogue systems into four modules (Wen et al., 2017; Ham et al., 2020; Peng et al., 2021): Natural Language Understanding (NLU) (Liu and Lane, 2016) that first comprehends users intents and extracts the slotsvalues pairs, Dialog State Tracker (DST) (Williams et al., 2013) that tracks the values of slots, Dialog Policy Learning (POL) (Peng et al., 2017, 2018) that decides the dialog actions, and Natural Language Generation (NLG) (Wen et al., 2015; Peng et al., 2020) that translates the dialog actions into a naturallanguageform. The DST module and the POL module usually are collectively referred to as the dialogue manager (DM) (Chen et al., 2017). These different modules can be trained independently or jointly in an endto-end manner (Wen et al., 2017; Liu and Lane, 2018; Ham et al., 2020; Peng et al., 2021). User simulator. The user simulator is also an agent but plays a user role. Different from dialogue systems, the user agent has a goal describing a target entity (e.g., a restaurant at a specific location) and should express its goal completely in an organized way by interacting with the system agent (Takanobu et al., 2020). Therefore, besides the modules of NLU, DM, and NLG like dialogue systems, the user agent should have another module called Goal Generator (Kreyssig et al., 2018), which is responsible for generating the users goal. Building a user simulator could usually use an agendabased approach (Schatzmann et al., 2007; Schatzmann and Young, 2009) designing handcrafted rules to mimic user behaviors or a modelbased approach such as neural networks (Asri et al., 2016; Kreyssig et al., 2018; Gur et al., 2018) learned on a corpus of dialogues. Training dialogue systems with a user simulator. To start a dialogue, a user agent will have an initial goal from its Goal Generator and then expresses its goal in natural languages. However, users goals are invisible to the system agent. Then the system agent tends to gradually understand the users utterances, query the database to find entities, and provide useful information to accomplish users task. When the database result returned by the system agent is empty, the user agent should learn to compromise and change its goal with the help of Goal Generator. When the dialogue ends, the user simulator will reward the system agent according to if it accomplishes the task. Then we could use the reward to update the system agent with RL algorithms (Tseng et al., 2021). 3 MUST: a Framework to Leverage Multiple User SimulaTors 3.1 Motivations to Use Multiple Simulators User simulators behave differently. Shi et al. (2019) implement six user simulators (AgenT, AgenR, AgenG, RNNT, RNNR, RNN3) with both 3Here we rename the user simulators of SLT, SLR, and SLE in Shi et al. (2019) as RNNT, RNNR, RNN for emphasizing the model structure of their DM modules.2(a) Success rates of different systems. (b) Dialog act distributions of different user simulators. Figure 1: (a) is the heat map on the success rates of system agents tested by different user simulators on 200 dialogues. (b) shows the dialog act distributions of Agendabased User Simulators (ABUS) and Neural networksbased User Simulators (NUS) provided by Shi et al. (2019). There exist seven user dialog acts annotated in the restaurant search task from MultiWOZ, as shown on the Yaxis. agendabased methods and neural networksbased methods on the popular restaurant search task from MultiWOZ (Budzianowski et al., 2018). From their experiments, we observed that the dialogue systems trained by different user simulators vary in their performances (i.e., the success rates tested by the same user simulators). For example, when interacting with the user simulator of AgenT, the success rates of the system agents trained by Agendabased user simulators (i.e., AgenT, AgenR, AgenG) are much higher than those of the system agents trained by RNNbased user simulators (i.e., RNNT, RNNR, RNN), see Fig. 1(a). The reason might be that these user simulators (i.e., with either handcrafted rules or datadriven learning in their DM modules) have different user dialog act distributions4(see Fig. 1(b)) which determine the dialogue state space explored by the dialogue system. One cannot stand for everyone. Users might behave differently, one could design different user simulators with specific user dialog act distributions, see Shi et al. (2019). A single user simulator learned on a taskoriented dialogue corpus can just represent one or a group of users, while the dialogue system needs to accomplish tasks from various human users in real scenarios. We argue that it is beneficial to utilize all different user simulators to train the dialogue system. By leveraging multiple user simulators that have different user dialog act distributions, the dialogue systems can explore a larger dialogue state space, which might 4The dialogue policy learning module is essential in both dialogue systems and user simulators. A policy module corresponds to a dialog act distribution since it decides to take which dialog act to respond to the current dialogue state. The user dialog act distribution behind a user simulator determines the diversity of the dialogue state space explored by dialogue systems; therefore it might affect the system performances.improve the ability of the learned dialogue system. 3.2 Some Preliminary Proposals for MUST We propose a framework called MUST, the core idea of which is to train a better dialogue system by leveraging Multiple UserSimula Tors simultaneously. There are several simple ways to implement our MUST, including a merging strategy (MUST merging ), aContinual Reinforcement Learningstrategy (MUST CRL), and a uniform adaption strategy (MUST uniform ). (I) MUST merging first samples some dialogues from each user simulator and the corresponding dialogue system trained by this simulator. Then it combines the collected dialogues to train a new user simulator for ensembling different user dialog act distributions. Finally, it uses this new user simulator to train the dialogue system with RL. (II) MUST CRL5treats each user simulator as an independent RL environment. It moves the trained system agent to another one (i.e., let the system agent interact with another user simulator) if the system has converged in the current environment. (III) MUST uniform allows the system agent have chances to interact with all user simulators simultaneously. Different from MUST CRL, MUST uniform puts all user simulators in a single RL environment and adopts the simplest way to specify different user simulators to train the dialogue system, which is to pick a user simulator among all user simulators with a uniform distribution for each iteration in the RL training. 5Continual Reinforcement Learning (CRL) (Khetarpal et al., 2020) is a sequential learning paradigm for training an agent with RL algorithms.3dynamic avoiding forgettingefficiencyadaption catastrophic MUST merging    MUST CRL    MUST uniform    MUST adaptive    Table 1: The comparison of different strategies for leveraging multiple user simulators. Challenges to leverage multiple user simulators. It is difficult to adaptively adjust weights of user simulators during training in MUST merging . Since the proportions of dialogues from each user simulator are fixed in MUST merging , user simulators might be welladapted and others might not. The MUST CRL strategy has a problem of catastrophic forgetting (Khetarpal et al., 2020) and would be sensitive to the order of different user agents interacting with the dialogue system, which might result in obtaining a suboptimal dialogue system. As Shi et al. (2019) shows, the system agents trained by different user simulators have different convergence speeds and converged performances. Namely, the system agent might be easily fitted to some user simulators but might be hardly fitted to others. A uniform distribution for the simulator selection under MUST uniform will result in inefficient training, since it would be unnecessary to assign the many training costs for easilyadapted user simulators. Overall, the challenging problems under MUST are 1) how to efficiently leverage multiple user simulators to train the system agent, and 2) avoiding the catastrophic forgetting issue. 4 MUST as a MAB Problem To tackle the challenges in MUST, we first formulate MUST as a Multiarmed bandit (MAB) problem, see 4.1. In 4.2, we propose a method called MUST adaptive to use an adaptivelyupdated distribution to replace the uniform distribution under the MUST uniform for accelerating the MUST training. We briefly compare these different implementations of MUST in Tab. 1. 4.1 Formulating MUST as a MAB Problem Adaptively specifying user simulators to train dialogue systems reminds us of a similar concept in machine learning, called boosting (Zhou, 2012). From a boosting point of view, one should increase the weights of weaklyperforming data examples and decrease the weights for wellperforming ones.In MUST, we accordingly assume that it should reduce the interactions between the dialogue system and those user simulators that the system has performed well; and meanwhile increase the interactions between the system and other user simulators that the system performs poorly. We refer to this strategy as boosting adaption . Meanwhile, we should also give some chances to all user simulators to relieve the catastrophic forgetting issue. We refer to this as uniform adaption . Such a tradeoff between boosting adaption and uniform adaption is similar to the the exploitation vs exploration tradeoff existing in the Multiarmed bandit (MAB) problem (Auer et al., 2002). Here, we interpret MUST as a MAB problem. We treat each user simulator as an arm. Suppose there are Karms (simulators), and each arm ihas a fixed but unknown reward distribution Riwith an expectation i. At each time step t= 1,2, ..., T , one must choose one of these Karms. We denote the arm pulled at time step tasit {1, ..., K}. After pulling an arm, it receives a reward xitdrawn from the arms underlying reward distribution. The decision makers objective is to maximize the cumulative expected reward over the time horizon T/summationdisplay t=1E[xit] =T/summationdisplay t=1it. (1) In MUST, the reward received in each armpulling step refers to the possible performance gain of the dialogue system after it interacts with a selected user simulator. A significant difference between the standard MAB problem and MUST is that the reward expectation of a user simulator (arm) in MUST is not static; it changes over time. For example, by consecutively interacting with the same user simulator, the performance gain (reward) of the system will decay since the system might be in saturation or overfitting to this simulator. Moreover, the performance gain of the system after interacting with a simulator might increase if the simulator has not been selected for a period. To deal with this difference , we should tailor the solution of MAB to the MUST framework. 4.2 Training with MUST adaptive To solve this MAB problem in MUST, we implement a method called MUST adaptive with a twophase procedure, as presented in Algorithm 1. MUST adaptive specifies user simulators in a4Algorithm 1: Implement MUST adaptive with the modified UCB1 algorithm Input: K fixed User simulators U={U1, U2,UK}and the values of hyperparameters Twarmup, T, e, d,  ; 1Initialization : randomly initialize System agent S; 2Initialization : initialize the simulator sampling distribution pas a uniform distribution. 3(1)Warmup phase: 4fort= 0, ..., T warmup1do 5 sample a simulator UjinUw.r.t. the distribution p; 6 synthesize a new dialogue using the system agent Sand the sampled Uj; 7 use the reward obtained for the dialogue to update Swith a RL algorithm; 8(2)Adaptive phase: 9fort= 0, ..., T1do 10 ift%e== 0 then 11 forj= 1, ..., K do 12 evaluate the performance i.e. the success rate xjof the agent Sby letting it interact dtimes with the simulator Uj; 13 update pbased on these success rates {x1, ...,xK}(see Eq. 2, Eq. 3, and Eq. 4); 14 else 15 sample a simulator UjinUw.r.t. the distribution p; 16 synthesizing a new dialogue using the system agent Sand the sampled Uj; 17 use the reward obtained for the dialogue to update Swith a RL algorithm; Output: The learned dialogue system S. uniform distribution, similar to the UCB16algorithm, to train the dialogue system Sin the first Twarmup steps (i.e., in the warmup phase ). After that, the adaptive phase will balance the boosting adaption and the uniform adaption by introducing an adaptivelyupdated distribution p, which is used to specify different user simulators to train the systemSin later RL training. To accelerate the RL training, intuitively, pis expected to assign lower weights to user simulators with which Salready performs well andhigher weights to those user simulators with which Sperforms poorly . (1) Warmup phase : in the first Twarmup dialogues, we use a uniform distribution to sample all user simulators to train the system agent S(lines 47). This phase is mainly used to warm up the dialogue system S. (2) Adaptive phase : the distribution pused to sample all user simulators will be adaptively updated. We call it as the adaptive phase . When this phase begins (i.e., t= 0), we will first evaluate the performance (i.e., the success rate xj, j {1,, K}) of the dialogue system Strained after the warmup phase . The success rate xjis obtained by letting Sinteract dtimes with the simulator Uj(e.g., j {1, ..., K}) and calculating the 6There exists an algorithm called UCB1 (Upper Confidence Bound 1 ) (Auer et al., 2002) that could solve the MAB problem. It first pulls each arm once in the first Ksteps, then will play the arm that could maximize the sum of two terms: it= arg max i/parenleft\\uf8ecig xi+/radical\\uf8ecig 2 lnt Ti,t/parenright\\uf8ecig fromt=K+ 1toT.success rates. Inspired by UCB1 (Auer et al., 2002), we design a calibrated performance expectation xjof the system agent Sinteracting with each user simulator Ujtaking exploration into consideration beyond pure exploitation: xj= xj/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright exploitation+/radical\\uf8ecigg 2 lnt Tj,t /bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright exploration, j {1, ..., K};(2) where xjis the success rate of the system agent S tested with user simulator Uj, and Tj,tis the number of times user simulator Ujhas been selected with so far. Then we normalize xjinto zj= 1/(xjmin({x1,,xK})), (3) Eq. 3 penalizes the user simulators with which the dialogue system already performs well in the expectation term. Where the hyperparameter is the smooth factor for distribution p={p1,,pK}  the larger is, the sharper pis. Each probability pjinpis calculated as pj=zj/summationtextK i=1zi. (4) In the following T1dialogues, we will specify all user simulators to train the system agent S with this distribution p(lines 1518). We will also evaluate the RL model Sfor every eepisodes (line 1012) and update the distribution pwith the new Ksuccess rates (line 13). Difference with the original UCB1. The main differences between our modified UCB1 algorithm5and the original UCB1 algorithm are twofold. First, we tailor the original UCB1 into our scenario by using Eq. 3 to penalize the user simulators with which the dialogue system has performed well. Secondly, we adopt a sampling schema based on a welldesigned distribution (see Eq. 4) instead of taking the arm with the highest expectation. This is to increase the diversity and flexibility of arm selection. 5 Experiments To verify the effectiveness of MUST, we benchmark the system agents trained either with a single user simulator or multiple user simulators (including MUST merging , MUST uniform , and MUST adaptive ). See MUST CRL in the App. C. 5.1 Experimental Setup Available user simulators. There are six user simulators provided by Shi et al. (2019), which are AgendaTemplate ( AgenT ), AgendaRetrieval (AgenR ), AgendaGeneration ( AgenG ), RNNTemplate ( RNNT ), RNNRetrieval ( RNNR ), RNNEnd2End ( RNN ) trained with different dialog planning and generation methods. The NLU modules of all six user simulators are using the RNN model. The DM modules of AgenT ,AgenR , and AgenG are rulebased methods. For the NLG module, these three simulators are using the template, retrieval, and generation methods respectively. The DM modules of RNNT , and RNNR are using Sequicity (Lei et al., 2018) as their backbones which is an RNNbased seq2seq model with copy mechanism. The NLG modules of these two simulators are using the template and retrieval methods respectively. The user simulator of RNN uses Sequicity as its backbone in an endto-end manner. Baselines. The baselines are the dialogue systems trained by each user simulator, including SysAgenT ,SysAgenR ,SysAgenG ,SysRNNT ,SysRNNR , and SysRNN . For a fair comparison, all system agents (including the systems trained by our MUST) have the same architecture described in Shi et al. (2019). See details in App. B.1. MultiWOZ Restaurant Domain Dataset. The original task in MultiWOZ (Budzianowski et al., 2018) is to model the system response. Shi et al. (2019) annotate the user intents and the userside dialog acts in the restaurant domain of MultiWOZ to build user simulators, which has a total of 1,310 dialogues. Moreover, we randomly simulate 2,000 dialogues from each rulebased simulator (i.e., AgenT, AgenR, AgenG) and their corresponding system agents respectively, and processe these dialogues to have the same annotation format as the MultiWOZ restaurant domain dataset. We denote this dataset asSimulated Agenda Dataset , which has a total of 6,000 dialogues. Evaluation Measures. A straightforward metric to evaluate dialogue systems is the success rate tested by each user simulator. We calculate the success rate between a user simulator and a system agent by sampling 200 dialogues. We exclude some user simulators in training MUST and test the systems with them as outof-domain evaluation . According to the previous study Gunasekara et al. (2020), there usually is a gap between automatic evaluations and human evaluations of dialogue systems. Therefore, we ask humans to converse with dialogue systems. Each dialogue system has conversed with 5 different users; each user has 10 dialogues. In total, we collect 50 dialogues for each dialogue system to calculate its success rate. See more details in App. B.5. 5.2 Implementations 5.2.1 Two new User Simulators We believe Pretrained Language Models (PLMs) might improve the capacity of user simulators since they have recently shown remarkable success in building taskoriented dialogue systems (Ham et al., 2020; Peng et al., 2021; HosseiniAsl et al., 2020). Here we implement another two user simulators using GPT (Radford et al., 2018, 2019). Building a user simulator using GPT is similar to building a ToD system with GPT. See more details in App. G. GPT Simulator. It is first finetuned on the simulated agenda dataset and then finetuned on the MultiWOZ restaurant domain dataset by leveraging GPT. This user simulator will be used to help implementing MUST. GPT IL Simulator. To implement the MUST merging strategy, similar to Imitation Learning (IL), we first train a new user simulator with dialogue sessions collected from different user simulators and their corresponding dialogue systems. We also learn this new user simulator based on GPT model and denote it as GPT IL. GPT ILis first finetuned on the simulated agenda dataset . Then we sample 1,400 dialogues from the6Dialogue SystemsIndomain evaluation Outof-domain evaluation All AgenT AgenR RNNT GPT AgenG RNNR RNN Avg. Std.Avg.Std. singleSysAgenT 97.5 54.040.0%98.50.5%78.04.9% 72.5 92.5 77.0 80.7 8.6 81.4 14.8 SysAgenR 96.01.5%90.0 98.50.5%80.51.8% 97.5 97.5 82.0 92.3 7.3 91.7 7.1 SysRNNT 30.568.7%23.074.4%99.0 75.57.9% 35.5 97.5 84.0 72.3 26.6 63.6 30.5 SysGPT 60.537.9%51.542.8%97.02.0%82.0 59.5 94.0 92.0 81.8 15.8 76.6 17.6 MUSTSysMUST merging 97.50.0% 83.57.2%94.54.6%80.51.8% 97.5 94.0 82.5 91.3 6.4 90.0 6.9 SysMUST uniform 97.50.0% 89.01.0%97.51.5%82.50.5% 96.5 96.0 87.5 93.4 4.2 92.4 5.6 SysMUST adaptive 97.50.0% 89.50.5%97.02.0%82.50.5% 96.5 97.5 90.0 94.7 3.3 92.9 5.3 [1] The underlined number represents the success rate between a user simulator and its corresponding dialogue system trained by this user simulator. The increasing and decreasing percentages (in red and green colors) use the underlined numbers as the base success rates. [2]() indicates by what percentages the success rate has decreased (increased) compared with the base success rate by interacting with the same user simulator. Table 2: The success rates of system agents testing on various user simulators. Each column represents a user simulator, each row represents a dialogue system trained with a specific simulator, e.g., SysAgenT means the system trained with AgenT. Each entry shows the success rate of a system agent when dealing with a user simulator. We use four simulators (AgenT, AgenR, RNNT, and GPT) to implement MUST uniform and MUST adaptive . simulated agenda dataset and merge them with 1,310 MultiWOZ restaurant domain dialogues to continue finetuning GPT IL. 5.2.2 Dialogue Systems SysGPT is trained with the single user simulator GPT. SysMUST merging is trained with GPT IL. SysMUST uniform is trained by the user simulators of AgenT, AgenR, RNNT, and GPT with a uniform sampling distribution. For training SysMUST adaptive7, the distribution pwill be adaptively updated using our modified UCB1 algorithm. We also train the SysMUST uniform and SysMUST adaptive by using different subsets of the user simulators for ablation studies in App. D. 5.3 Experimental Results Automatic Evaluation. As seen in Tab. 2, SysMUST uniform and SysMUST adaptive outperform the dialogue systems (SysAgenT, SysAgenR, SysRNNT, and SysGPT) trained by a single user simulator in the overall performance, demonstrating the superiority of leveraging multiple user simulators. Especially, SysMUST adaptive has a 1.2 absolute value improvement (92.9 vs. 91.7) averagely over the previous SOTA system SysAgenR. Observing that SysMUST merging is not as competitive as SysMUST uniform and SysMUST adaptive , this comparison shows that the merging strategy cannot effectively leverage multiple user simulators. Inindomain evaluation , the performances of systems (SysAgenT, SysAgenR, SysRNNT, and SysGPT) trained by a single user simulator drop a lot when testing with a different simulator. It requires us to delicately select a suitable user simula7See implementations of dialogue systems in App. B.2 and policy gradient algorithm in App. B.3.Dialogue Systemshuman evaluation singleSysAgenT 76.0 SysAgenR 84.0 SysRNNT 34.0 SysGPT 58.0 MUSTSysMUST merging 90.0 SysMUST uniform 92.0 SysMUST adaptive 92.0 Table 3: Human evaluation. tor for obtaining a good dialogue system. However, users might be multifacet or even unknown, making the selection even more difficult. Therefore, it is essential to leverage multiple user simulators when training dialogue systems. At least, the performance gap of dialogue systems trained with our MUST becomes smaller than without MUST, see the percentages labeled in green and red colors. Inoutof-domain evaluation where the user simulators used for testing the systems are unseen by our MUST, SysMUST uniform and SysMUST adaptive achieve at most 2.4 absolute value improvement over SysAgenR. This evidences that MUST has a better generalization ability for interacting with unseen user simulators. Moreover, the dialogue systems (SysMUST merging , SysMUST uniform , and SysMUST adaptive ) trained with the proposed MUST approaches have lower standard deviations, which indicates that they are more robust to the diversity of user simulators. Human Evaluation. In Tab. 3, the human evaluation results show that our SysMUST uniform and SysMUST adaptive largely outperform the other dialogue systems when interacting with real users. The consistency between automatic evaluations and human evaluations evidences the effectiveness of our proposed MUST.7(a) The learning curves (b) AgenR (c) AgenT (d) GPT (e) RNNT Figure 2: The learning curves of SysMUST uniform and SysMUST adaptive . (a) shows their average success rates tested with all user simulators (AgenT, AgenR, RNNT, and GPT). The success rates of them tested with each user simulator are shown in (b)-(e). (a) The sampling proportion of simulators. (b) Variations of the sampling proportions (in every 2000 steps) of simulators. Figure 3: The sampling proportions of user simulators in average (a) and in time horizon (b). 5.4 Analysis and Discussions Convergences of MUST uniform and MUST adaptive .In Fig. 2, we show the learning curves of SysMUST uniform and SysMUST adaptive in 100,000 steps; the first 40,000 steps are in the warmup phase for SysMUST adaptive . From Fig. 2(a), we can see that training the dialogue system with AgenT, AgenR, RNNT, and GPT by MUST adaptive converges faster than by MUST uniform . We do ablation studies on our modified UCB1 algorithm to help understanding the designed distribution p, see details in App. E. We further plot the performances of the dialogue system tested by each user simulator in the RL training in Fig. 2(b)-2(e). Visualization on MUST adaptive .Let us define the adaptation difficulty of a user simulator using how many steps it must take to train the dialogue system with this user simulator until it converges. The adaptation difficulty of all user simulators could be ranked like AgenR >AgenT >GPT>RNNT according to Fig. 2(b)-2(e). To check whether MUST adaptive tends to sample harderto-adapt user simulators more times in the adaptive phase , as assumed in 4.2, we visualize the sampling proportions of alluser simulators in Fig. 3(a). We could observe that AgenR was sampled with 45.1% (the biggest proportion) and it is indeed the hardest user simulator that can be adapted by the system; RNNT has the smallest sampling proportion and it is the easiest user simulator that can be adapted by the system. The consistency between the adaptation difficulty and sampling proportions for these four user simulators evidences our assumption in 4.2. Fig. 3(b) visualizes the variations of the sampling distributions of user simulators. Interestingly, it shows that AgenR and AgenT are competitive with the GPT simulator; while RNNT and GPT are cooperative with each other. This might be because both RNNT and GPT simulators are learned from the dialogue corpus and might share some similar behaviors. 6 Conclusion In this paper, we propose a framework named MUST to improve dialogue systems by using multiple user simulators simultaneously. We discuss several simple methods to implement MUST, which is either inflexible or inefficient. Therefore, we formulate MUST as a Multiarmed bandits (MAB) problem, based on which we propose a novel implementation called MUST adaptive . The experimental results on the restaurant search task from8MultiWOZ demonstrate that MUST can largely improve the system agent upon baselines, especially when tested with unseen user simulators. Moreover, MUST adaptive is more efficient than other implementations. Limitation The main limitation of this work is that we only conduct our experiments on the restaurant domain of the MultiWOZ since we can only find multiple user simulators from Shi et al. (2019) and they build these simulators only on the restaurant search task. In future work, we plan to apply our proposed methods to multidomain scenarios. Ethics Statement There are no ethicsrelated issues in this paper. The data and other related resources in this work are opensource and commonlyused by many existing work. Acknowledgements Part of this work was done when the first author worked at Huawei Noahs Ark Lab. Besides, this work is supported by the Chinese KeyArea Research and Development Program of Guangdong Province (2020B0101350001), the Shenzhen Science and Technology Program (JCYJ20220818103001002), the Guangdong Provincial Key Laboratory of Big Data Computing, The Chinese University of Hong Kong, Shenzhen, Shenzhen Key Research Project (C10120230151) and Shenzhen Doctoral Startup Funding (RCBS20221008093330065). We would like to thank Zichao Li, Chen Zhang, and Dong Yang for their helpful discussions. Moreover, we thank anonymous reviewers for their valuable suggestions.Conclusion In this paper, we propose a framework named MUST to improve dialogue systems by using multiple user simulators simultaneously. We discuss several simple methods to implement MUST, which is either inflexible or inefficient. Therefore, we formulate MUST as a Multiarmed bandits (MAB) problem, based on which we propose a novel implementation called MUST adaptive . The experimental results on the restaurant search task from8MultiWOZ demonstrate that MUST can largely improve the system agent upon baselines, especially when tested with unseen user simulators. Moreover, MUST adaptive is more efficient than other implementations. Limitation The main limitation of this work is that we only conduct our experiments on the restaurant domain of the MultiWOZ since we can only find multiple user simulators from Shi et al. (2019) and they build these simulators only on the restaurant search task. In future work, we plan to apply our proposed methods to multidomain scenarios. Ethics Statement There are no ethicsrelated issues in this paper. The data and other related resources in this work are opensource and commonlyused by many existing work. Acknowledgements Part of this work was done when the first author worked at Huawei Noahs Ark Lab. Besides, this work is supported by the Chinese KeyArea Research and Development Program of Guangdong Province (2020B0101350001), the Shenzhen Science and Technology Program (JCYJ20220818103001002), the Guangdong Provincial Key Laboratory of Big Data Computing, The Chinese University of Hong Kong, Shenzhen, Shenzhen Key Research Project (C10120230151) and Shenzhen Doctoral Startup Funding (RCBS20221008093330065). We would like to thank Zichao Li, Chen Zhang, and Dong Yang for their helpful discussions. Moreover, we thank anonymous reviewers for their valuable suggestions.Abstract User simulators are agents designed to imitate human users; recent advances have found that Taskoriented Dialogue (ToD) systems optimized toward a user simulator could better satisfy the need of human users. However, this might result in a suboptimal ToD system if it is tailored to only one ad hoc user simulator, since human users can behave differently. In this paper, we propose a framework called MUST1to optimize ToD systems via leveraging Multiple UserSimula Tors. The main challenges of implementing the MUST are 1) how to adaptively determine which user simulator to interact with the ToD system at each optimization step, since the ToD system might be overfitted to some specific user simulators, and simultaneously underfitted to some others; 2) how to avoid catastrophic forgetting of the adaption for a simulator that is not selected for several consecutive optimization steps. To tackle these challenges, we formulate MUST as a Multiarmed bandits (MAB) problem and provide a method called MUST adaptive that balances i) the boosting adaption for adaptive interactions between different user simulators and the ToD system andii) the uniform adaption to avoid the catastrophic forgetting issue. With both automatic evaluations and human evaluations, our experimental results on MultiWOZ show that the dialogue system trained by MUST achieves a better performance than those trained by a single user simulator. It also has a better generalization ability when testing with unseen user simulators. 1Introduction Taskoriented dialogue systems aim to help users accomplish their various tasks (e.g., restaurant reservations) through natural language conversations. Training taskoriented dialogue systems in 1The code is available at https://github.com/ kiseliu/must .supervised learning approaches often requires a large amount of expertlabeled dialogues, however collecting these dialogues is usually expensive and timeconsuming. Moreover, even with a large amount of dialogue data, some dialogue states may not be explored sufficiently for dialogue systems2'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "41a3285a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "\n",
    "# Assuming 'df' is your DataFrame\n",
    "data = Dataset.from_pandas(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2fbdc16f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9aed15983f3c4a32b2c0120316f7830d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Input is not valid. Should be a string, a list/tuple of strings or a list/tuple of integers.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_32328\\3786131352.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m# Apply the tokenizer to the dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mtokenized_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokenize_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatched\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\datasets\\arrow_dataset.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    591\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m\"Dataset\"\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"self\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m         \u001b[1;31m# apply actual function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 593\u001b[1;33m         \u001b[0mout\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Dataset\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"DatasetDict\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    594\u001b[0m         \u001b[0mdatasets\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Dataset\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mdataset\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\datasets\\arrow_dataset.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    556\u001b[0m         }\n\u001b[0;32m    557\u001b[0m         \u001b[1;31m# apply actual function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 558\u001b[1;33m         \u001b[0mout\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Dataset\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"DatasetDict\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    559\u001b[0m         \u001b[0mdatasets\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Dataset\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m         \u001b[1;31m# re-apply format to the output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\datasets\\arrow_dataset.py\u001b[0m in \u001b[0;36mmap\u001b[1;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[0;32m   3103\u001b[0m                     \u001b[0mdesc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdesc\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;34m\"Map\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3104\u001b[0m                 ) as pbar:\n\u001b[1;32m-> 3105\u001b[1;33m                     \u001b[1;32mfor\u001b[0m \u001b[0mrank\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontent\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mDataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_map_single\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mdataset_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3106\u001b[0m                         \u001b[1;32mif\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3107\u001b[0m                             \u001b[0mshards_done\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\datasets\\arrow_dataset.py\u001b[0m in \u001b[0;36m_map_single\u001b[1;34m(shard, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset)\u001b[0m\n\u001b[0;32m   3480\u001b[0m                         )  # Something simpler?\n\u001b[0;32m   3481\u001b[0m                         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3482\u001b[1;33m                             batch = apply_function_on_filtered_inputs(\n\u001b[0m\u001b[0;32m   3483\u001b[0m                                 \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3484\u001b[0m                                 \u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\datasets\\arrow_dataset.py\u001b[0m in \u001b[0;36mapply_function_on_filtered_inputs\u001b[1;34m(pa_inputs, indices, check_same_num_examples, offset)\u001b[0m\n\u001b[0;32m   3359\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mwith_rank\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3360\u001b[0m                 \u001b[0madditional_args\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mrank\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3361\u001b[1;33m             \u001b[0mprocessed_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfn_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0madditional_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfn_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3362\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocessed_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLazyDict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3363\u001b[0m                 processed_inputs = {\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_32328\\3786131352.py\u001b[0m in \u001b[0;36mtokenize_function\u001b[1;34m(examples)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# Function to tokenize the data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtokenize_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexamples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexamples\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'all'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"max_length\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m512\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m# Apply the tokenizer to the dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\tokenization_utils_base.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m   2870\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_target_context_manager\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2871\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_switch_to_input_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2872\u001b[1;33m             \u001b[0mencodings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_one\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext_pair\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtext_pair\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mall_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2873\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtext_target\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2874\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_switch_to_target_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\tokenization_utils_base.py\u001b[0m in \u001b[0;36m_call_one\u001b[1;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m   2956\u001b[0m                 )\n\u001b[0;32m   2957\u001b[0m             \u001b[0mbatch_text_or_text_pairs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext_pair\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mtext_pair\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2958\u001b[1;33m             return self.batch_encode_plus(\n\u001b[0m\u001b[0;32m   2959\u001b[0m                 \u001b[0mbatch_text_or_text_pairs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_text_or_text_pairs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2960\u001b[0m                 \u001b[0madd_special_tokens\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0madd_special_tokens\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\tokenization_utils_base.py\u001b[0m in \u001b[0;36mbatch_encode_plus\u001b[1;34m(self, batch_text_or_text_pairs, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m   3147\u001b[0m         )\n\u001b[0;32m   3148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3149\u001b[1;33m         return self._batch_encode_plus(\n\u001b[0m\u001b[0;32m   3150\u001b[0m             \u001b[0mbatch_text_or_text_pairs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_text_or_text_pairs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3151\u001b[0m             \u001b[0madd_special_tokens\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0madd_special_tokens\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\tokenization_utils.py\u001b[0m in \u001b[0;36m_batch_encode_plus\u001b[1;34m(self, batch_text_or_text_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m    801\u001b[0m                 \u001b[0mids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpair_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mids_or_pair_ids\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    802\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 803\u001b[1;33m             \u001b[0mfirst_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_input_ids\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    804\u001b[0m             \u001b[0msecond_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_input_ids\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpair_ids\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mpair_ids\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    805\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfirst_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msecond_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\tokenization_utils.py\u001b[0m in \u001b[0;36mget_input_ids\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m    781\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 783\u001b[1;33m                 raise ValueError(\n\u001b[0m\u001b[0;32m    784\u001b[0m                     \u001b[1;34m\"Input is not valid. Should be a string, a list/tuple of strings or a list/tuple of integers.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    785\u001b[0m                 )\n",
      "\u001b[1;31mValueError\u001b[0m: Input is not valid. Should be a string, a list/tuple of strings or a list/tuple of integers."
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2-large')\n",
    "\n",
    "# Ensure padding token is set if using a model that doesn't have it by default\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Function to tokenize the data\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['all'], truncation=True, padding=\"max_length\", max_length=512)\n",
    "\n",
    "# Apply the tokenizer to the dataset\n",
    "tokenized_data = data.map(tokenize_function, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50016609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and validation sets\n",
    "train_test_split = tokenized_data.train_test_split(test_size=0.5)  # 50% for testing\n",
    "train_dataset = train_test_split['train']\n",
    "test_dataset = train_test_split['test']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5285afd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08994e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3bc599",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, Trainer, TrainingArguments\n",
    "\n",
    "# Load the model\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2-large')\n",
    "\n",
    "# Setup training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          # Where to store the final model\n",
    "    evaluation_strategy=\"epoch\",     # Evaluation is done at the end of each epoch\n",
    "    learning_rate=5e-5,\n",
    "    weight_decay=0.01,\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=4,   # Adjust based on your GPU memory\n",
    "    per_device_eval_batch_size=8,\n",
    "    warmup_steps=500,\n",
    "    save_strategy=\"epoch\",\n",
    "    disable_tqdm=False,\n",
    "    logging_dir='./logs',            # Where to store logs\n",
    "    logging_steps=10,\n",
    ")\n",
    "\n",
    "# Initialize the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "# Start training\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca174f59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
